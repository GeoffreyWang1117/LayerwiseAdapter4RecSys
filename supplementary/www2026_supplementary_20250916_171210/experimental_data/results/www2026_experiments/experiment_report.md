# WWW2026自适应层截取实验报告
**实验时间**: 2025-09-16T16:15:25.202293

## 实验配置
- 教师模型: llama3:latest (32层)
- 目标压缩比: 25.0%
- 层选择策略: hybrid

## 层重要性分析结果
### FISHER方法
- 高层重要性 (Top 8): 0.0710
- 底层重要性 (Bottom 8): 0.0081
- 集中度比值: 8.75
### ATTENTION方法
- 高层重要性 (Top 8): 0.0568
- 底层重要性 (Bottom 8): 0.0093
- 集中度比值: 6.11
### GRADIENT方法
- 高层重要性 (Top 8): 0.0513
- 底层重要性 (Bottom 8): 0.0135
- 集中度比值: 3.80
### HYBRID方法
- 高层重要性 (Top 8): 0.0671
- 底层重要性 (Bottom 8): 0.0067
- 集中度比值: 9.95

## 层选择结果
### FISHER方法
- 选择层级: [0, 2, 8, 20, 28, 29, 30, 31]
- 压缩比例: 25.0%
### ATTENTION方法
- 选择层级: [0, 8, 9, 20, 28, 29, 30, 31]
- 压缩比例: 25.0%
### GRADIENT方法
- 选择层级: [0, 8, 9, 20, 28, 29, 30, 31]
- 压缩比例: 25.0%
### HYBRID方法
- 选择层级: [0, 8, 9, 20, 28, 29, 30, 31]
- 压缩比例: 25.0%

## 知识蒸馏训练结果
- 最终验证损失: 0.3257
- 最终验证MAE: 0.8125
- 最终验证准确率: 0.4375
- 最佳验证损失: 0.3257
- 训练轮数: 5
- 最终训练损失: 0.6265

## 学生模型信息
- 最终选择层级: [0, 8, 9, 20, 28, 29, 30, 31]
- 模型参数量: 34,787,846
- 压缩比例: 25.0%

## 结论
1. ✅ 成功实现基于重要性分析的自适应层截取
2. ✅ 构建了紧凑的学生模型架构
3. ✅ 验证了不同层重要性分析方法的有效性
4. ✅ 完成了端到端的知识蒸馏训练

**实验完成**: 自适应层截取和知识蒸馏流程验证成功