#!/usr/bin/env python3
"""
Enhanced Amazon Reviews Ollama Recommender
æ”¹è¿›ç‰ˆAmazonæ¨èç³»ç»Ÿï¼Œä½¿ç”¨ollamaè¿›è¡Œæ™ºèƒ½æ¨è
"""

import pandas as pd
import numpy as np
import requests
import json
import os
import time
from typing import List, Dict, Any
import random
from datetime import datetime

class EnhancedAmazonRecommender:
    def __init__(self, data_dir: str = "dataset/amazon", model_name: str = "qwen3:latest"):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆAmazonæ¨èå™¨
        """
        self.data_dir = data_dir
        self.model_name = model_name
        self.ollama_url = "http://localhost:11434/api/generate"
        
        # å¯ç”¨çš„æ•°æ®é›†ç±»åˆ«ï¼ˆæŒ‰å¤§å°æ’åºï¼Œå°çš„ä¼˜å…ˆï¼‰
        self.categories = [
            "All_Beauty", "Movies_and_TV", "Office_Products", 
            "Toys_and_Games", "Sports_and_Outdoors", "Arts_Crafts_and_Sewing",
            "Automotive", "Electronics", "Home_and_Kitchen", "Books"
        ]
        
        self.products_cache = {}
        self.reviews_cache = {}
        
    def query_ollama_simple(self, prompt: str, max_tokens: int = 100) -> str:
        """
        ç®€åŒ–çš„ollamaæŸ¥è¯¢ï¼Œå‡å°‘è¶…æ—¶é—®é¢˜
        """
        try:
            payload = {
                "model": self.model_name,
                "prompt": f"{prompt}\n\nPlease provide a concise response (max {max_tokens} words):",
                "stream": False,
                "options": {
                    "temperature": 0.5,
                    "num_predict": max_tokens,
                    "stop": ["\\n\\n", "---", "###"]
                }
            }
            
            response = requests.post(self.ollama_url, json=payload, timeout=20)
            response.raise_for_status()
            
            result = response.json()
            return result.get('response', '').strip()
            
        except Exception as e:
            print(f"âš ï¸ Ollama query failed: {e}")
            return "User profile unavailable due to service error"
    
    def load_small_sample(self, category: str, max_products: int = 200, max_reviews: int = 500):
        """
        åŠ è½½å°æ ·æœ¬æ•°æ®ä»¥å¿«é€Ÿæ¼”ç¤º
        """
        print(f"ğŸ“Š Loading small sample for {category}...")
        
        meta_file = os.path.join(self.data_dir, f"{category}_meta.parquet")
        reviews_file = os.path.join(self.data_dir, f"{category}_reviews.parquet")
        
        if not os.path.exists(meta_file) or not os.path.exists(reviews_file):
            print(f"âŒ Files missing for {category}")
            return None, None
            
        try:
            # åŠ è½½äº§å“æ•°æ®
            print(f"   ğŸ“¦ Loading products from {meta_file}...")
            meta_df = pd.read_parquet(meta_file, columns=['parent_asin', 'title', 'price', 'average_rating'])
            
            # è¿‡æ»¤å¹¶é‡‡æ ·
            meta_df = meta_df.dropna(subset=['title'])
            meta_df = meta_df[meta_df['title'].str.len() > 10]  # è¿‡æ»¤æ ‡é¢˜å¤ªçŸ­çš„
            
            if len(meta_df) > max_products:
                meta_df = meta_df.sample(n=max_products, random_state=42)
            
            # åŠ è½½è¯„è®ºæ•°æ®
            print(f"   ğŸ’¬ Loading reviews from {reviews_file}...")
            product_ids = set(meta_df['parent_asin'].tolist())
            
            # ç›´æ¥åŠ è½½è¯„è®ºæ•°æ®ï¼ˆé€‰æ‹©æ€§åˆ—ï¼‰
            try:
                reviews_df = pd.read_parquet(reviews_file, columns=['parent_asin', 'user_id', 'rating', 'text'])
                reviews_df = reviews_df[reviews_df['parent_asin'].isin(product_ids)]
                
                # å¦‚æœæ•°æ®å¤ªå¤§ï¼Œè¿›è¡Œé‡‡æ ·
                if len(reviews_df) > max_reviews:
                    reviews_df = reviews_df.sample(n=max_reviews, random_state=42)
                    
            except Exception as e:
                print(f"   âš ï¸ Error loading reviews: {e}")
                reviews_df = pd.DataFrame()
            
            self.products_cache[category] = meta_df
            self.reviews_cache[category] = reviews_df
            
            print(f"âœ… Loaded {len(meta_df)} products and {len(reviews_df)} reviews")
            return meta_df, reviews_df
            
        except Exception as e:
            print(f"âŒ Error loading {category}: {e}")
            return None, None
    
    def create_simple_user_profile(self, user_reviews: pd.DataFrame) -> str:
        """
        åˆ›å»ºç®€åŒ–çš„ç”¨æˆ·ç”»åƒ
        """
        if user_reviews.empty:
            return "New user with no review history"
        
        avg_rating = user_reviews['rating'].mean()
        review_count = len(user_reviews)
        
        # ç®€åŒ–çš„ç”¨æˆ·ç”»åƒç”Ÿæˆ
        if avg_rating >= 4.5:
            satisfaction = "highly satisfied"
        elif avg_rating >= 3.5:
            satisfaction = "moderately satisfied"
        else:
            satisfaction = "critical"
        
        # æå–æœ€è¿‘çš„è¯„è®ºæ–‡æœ¬å…³é”®è¯
        recent_text = ""
        if 'text' in user_reviews.columns and not user_reviews['text'].empty:
            recent_reviews = user_reviews['text'].dropna().head(2)
            recent_text = " ".join(recent_reviews.astype(str))[:200]
        
        # æ„å»ºç®€åŒ–prompt
        prompt = f"""Create a brief user profile based on:
- {review_count} reviews with {avg_rating:.1f}/5.0 average rating
- User is {satisfaction} with purchases
- Recent feedback: {recent_text[:100]}...

User profile (1 sentence):"""

        profile = self.query_ollama_simple(prompt, max_tokens=50)
        
        # å›é€€åˆ°ç®€å•æè¿°
        if not profile or len(profile) < 10:
            profile = f"{satisfaction.title()} customer with {review_count} reviews (avg: {avg_rating:.1f}/5)"
        
        return profile
    
    def smart_recommend(self, category: str, user_profile: str, top_k: int = 3) -> List[Dict]:
        """
        æ™ºèƒ½æ¨èäº§å“
        """
        if category not in self.products_cache:
            return []
        
        products_df = self.products_cache[category]
        
        # é€‰æ‹©é«˜è´¨é‡äº§å“ä½œä¸ºå€™é€‰
        quality_products = products_df.copy()
        
        # ä¼˜å…ˆé€‰æ‹©æœ‰è¯„åˆ†çš„äº§å“
        if 'average_rating' in quality_products.columns:
            quality_products = quality_products.dropna(subset=['average_rating'])
            quality_products = quality_products[quality_products['average_rating'] >= 3.0]
        
        # é€‰æ‹©å€™é€‰äº§å“
        candidates = quality_products.sample(n=min(10, len(quality_products))).to_dict('records')
        
        recommendations = []
        for i, product in enumerate(candidates[:top_k]):
            title = str(product.get('title', 'Unknown Product'))[:80]
            price = product.get('price', 'N/A')
            rating = product.get('average_rating', 'N/A')
            
            # ç®€å•çš„æ¨èç†ç”±
            if isinstance(rating, (int, float)) and rating >= 4.0:
                reason = f"High-rated product ({rating}/5) matching user preferences"
            elif price and price != 'N/A':
                reason = f"Well-priced option at ${price}"
            else:
                reason = "Popular product in category"
            
            recommendations.append({
                'rank': i + 1,
                'asin': product.get('parent_asin', ''),
                'title': title,
                'price': price,
                'rating': rating,
                'explanation': reason
            })
        
        return recommendations
    
    def run_quick_demo(self, category: str = "All_Beauty", num_users: int = 2):
        """
        è¿è¡Œå¿«é€Ÿæ¼”ç¤º
        """
        print(f"ğŸš€ Enhanced Amazon Recommendation System")
        print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¤– Model: {self.model_name}")
        print(f"ğŸ“¦ Category: {category}")
        print("=" * 60)
        
        # åŠ è½½å°æ ·æœ¬æ•°æ®
        products_df, reviews_df = self.load_small_sample(category, max_products=200, max_reviews=300)
        if products_df is None:
            print("âŒ Demo failed - could not load data")
            return None
        
        print(f"\nğŸ“ˆ Dataset Statistics:")
        print(f"   â€¢ Products: {len(products_df)}")
        print(f"   â€¢ Reviews: {len(reviews_df)}")
        print(f"   â€¢ Unique users: {reviews_df['user_id'].nunique() if not reviews_df.empty else 0}")
        
        if reviews_df.empty:
            print("âš ï¸ No reviews available for recommendation demo")
            return None
        
        # é€‰æ‹©æ´»è·ƒç”¨æˆ·
        user_review_counts = reviews_df['user_id'].value_counts()
        active_users = user_review_counts[user_review_counts >= 1].index[:num_users]
        
        results = []
        
        for i, user_id in enumerate(active_users):
            print(f"\nğŸ‘¤ User {i+1}/{len(active_users)}")
            print(f"   ID: {user_id}")
            print("-" * 40)
            
            # ç”¨æˆ·è¯„è®ºå†å²
            user_reviews = reviews_df[reviews_df['user_id'] == user_id]
            print(f"ğŸ“ Reviews: {len(user_reviews)}")
            print(f"ğŸ“Š Avg Rating: {user_reviews['rating'].mean():.1f}/5.0")
            
            # ç”Ÿæˆç”¨æˆ·ç”»åƒ
            print("ğŸ§  Creating user profile...")
            user_profile = self.create_simple_user_profile(user_reviews)
            print(f"ğŸ‘¤ Profile: {user_profile}")
            
            # ç”Ÿæˆæ¨è
            print("ğŸ¯ Generating recommendations...")
            recommendations = self.smart_recommend(category, user_profile, top_k=3)
            
            print(f"\nğŸ“‹ Recommendations:")
            for rec in recommendations:
                print(f"   {rec['rank']}. {rec['title']}")
                print(f"      ğŸ’° Price: {rec['price']} | â­ Rating: {rec['rating']}")
                print(f"      ğŸ’¡ {rec['explanation']}")
                print()
            
            results.append({
                'user_id': user_id,
                'profile': user_profile,
                'recommendations': recommendations,
                'stats': {
                    'review_count': len(user_reviews),
                    'avg_rating': float(user_reviews['rating'].mean())
                }
            })
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f"enhanced_amazon_rec_{category}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nâœ… Demo completed successfully!")
        print(f"ğŸ’¾ Results saved to: {output_file}")
        print(f"ğŸ“Š Processed {len(results)} users with recommendations")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Enhanced Amazon Ollama Recommender")
    print("=" * 50)
    
    # æ£€æŸ¥ollamaæœåŠ¡
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        print("âœ… Ollama service is running")
    except Exception as e:
        print(f"âŒ Ollama service issue: {e}")
        print("   Please ensure ollama is running: ollama serve")
        return
    
    # åˆå§‹åŒ–æ¨èå™¨
    recommender = EnhancedAmazonRecommender(model_name="qwen3:latest")
    
    # è¿è¡Œå¿«é€Ÿæ¼”ç¤º
    print("\nğŸš€ Starting quick recommendation demo...")
    results = recommender.run_quick_demo(category="All_Beauty", num_users=3)
    
    if results:
        print(f"\nğŸ‰ Demo successful!")
        print(f"   âœ“ Generated personalized recommendations")
        print(f"   âœ“ Used ollama for intelligent profiling")
        print(f"   âœ“ Processed Amazon review data")
    else:
        print(f"\nâŒ Demo encountered issues")

if __name__ == "__main__":
    main()
