#!/usr/bin/env python3
"""
Base Recommender for Layerwise Knowledge Distillation
åŸºäºFisherä¿¡æ¯çŸ©é˜µçš„å±‚çº§çŸ¥è¯†è’¸é¦æ¨èç³»ç»ŸåŸºç±»

WWW2026ç ”ç©¶ç›®æ ‡ï¼š
- ä½¿ç”¨Llama3ä½œä¸ºTeacheræ¨¡å‹ï¼ˆç»éªŒè¯æ€§èƒ½æœ€ä¼˜ï¼‰
- é›†æˆFisherä¿¡æ¯è®¡ç®—ç”¨äºå±‚çº§æƒé‡åˆ†é…
- æ”¯æŒå¤šç§æ¨èä»»åŠ¡çš„çŸ¥è¯†è’¸é¦
"""

import pandas as pd
import numpy as np
import requests
import json
import os
import torch
import torch.nn as nn
from typing import List, Dict, Any, Optional, Tuple
import random
from datetime import datetime
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class RecommendationConfig:
    """æ¨èç³»ç»Ÿé…ç½®"""
    # æ¨¡å‹é…ç½®
    teacher_model: str = "llama3:latest"  # WWW2026æŒ‡å®šçš„æœ€ä¼˜Teacheræ¨¡å‹
    ollama_url: str = "http://localhost:11434/api/generate"
    temperature: float = 0.1              # ä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
    max_tokens: int = 512
    timeout: int = 30
    
    # æ¨èå‚æ•°
    top_k: int = 5                        # æ¨èæ•°é‡
    candidate_size: int = 50              # å€™é€‰é›†å¤§å°
    user_profile_max_length: int = 500    # ç”¨æˆ·ç”»åƒæœ€å¤§é•¿åº¦
    
    # Fisheré›†æˆå‚æ•°
    use_fisher_weighting: bool = True     # æ˜¯å¦ä½¿ç”¨Fisheræƒé‡
    fisher_temperature: float = 2.0       # Fisheræƒé‡æ¸©åº¦
    semantic_boost: float = 1.5           # è¯­ä¹‰å±‚å¢å¼º
    
    # æ•°æ®é…ç½®
    data_dir: str = "dataset/amazon"
    sample_size: int = 1000
    cache_dir: str = "cache/recommendations"

class BaseRecommender(ABC):
    """
    åŸºç¡€æ¨èå™¨æŠ½è±¡ç±»
    
    WWW2026æ¡†æ¶è®¾è®¡ï¼š
    - æ ‡å‡†åŒ–Teacheræ¨¡å‹æ¥å£ï¼ˆLlama3ï¼‰
    - é›†æˆFisherä¿¡æ¯æƒé‡è®¡ç®—
    - æ”¯æŒå±‚çº§çŸ¥è¯†è’¸é¦æµç¨‹
    """
    
    def __init__(self, config: Optional[RecommendationConfig] = None):
        """
        åˆå§‹åŒ–åŸºç¡€æ¨èå™¨
        
        Args:
            config: æ¨èé…ç½®
        """
        self.config = config or RecommendationConfig()
        
        # æ•°æ®ç¼“å­˜
        self.products_cache = {}
        self.reviews_cache = {}
        self.user_profiles_cache = {}
        
        # å¯ç”¨çš„Amazonæ•°æ®é›†ç±»åˆ«
        self.categories = [
            "All_Beauty", "Arts_Crafts_and_Sewing", "Automotive", 
            "Books", "Electronics", "Home_and_Kitchen",
            "Movies_and_TV", "Office_Products", "Sports_and_Outdoors", 
            "Toys_and_Games"
        ]
        
        # Fisheræƒé‡ç¼“å­˜ï¼ˆç”¨äºè’¸é¦ï¼‰
        self.fisher_weights_cache = {}
        
        # åˆå§‹åŒ–ç¼“å­˜ç›®å½•
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)
        
        logger.info(f"åŸºç¡€æ¨èå™¨åˆå§‹åŒ–å®Œæˆ - Teacheræ¨¡å‹: {self.config.teacher_model}")
    
    @abstractmethod
    def generate_recommendations(self, 
                               user_profile: str, 
                               category: str, 
                               top_k: int = None) -> List[Dict]:
        """
        ç”Ÿæˆæ¨èç»“æœï¼ˆæŠ½è±¡æ–¹æ³•ï¼‰
        
        Args:
            user_profile: ç”¨æˆ·ç”»åƒ
            category: äº§å“ç±»åˆ«  
            top_k: æ¨èæ•°é‡
            
        Returns:
            æ¨èç»“æœåˆ—è¡¨
        """
        pass
    
    @abstractmethod
    def compute_recommendation_features(self, 
                                     user_profile: str, 
                                     items: List[Dict]) -> torch.Tensor:
        """
        è®¡ç®—æ¨èç‰¹å¾ï¼ˆç”¨äºFisherä¿¡æ¯è®¡ç®—ï¼‰
        
        Args:
            user_profile: ç”¨æˆ·ç”»åƒ
            items: å€™é€‰ç‰©å“åˆ—è¡¨
            
        Returns:
            ç‰¹å¾å¼ é‡
        """
        pass
        
    def load_sample_data(self, category: str, sample_size: int = None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        åŠ è½½æŒ‡å®šç±»åˆ«çš„æ ·æœ¬æ•°æ®
        
        Args:
            category: æ•°æ®ç±»åˆ«
            sample_size: é‡‡æ ·å¤§å°
            
        Returns:
            (products_df, reviews_df): äº§å“å’Œè¯„è®ºæ•°æ®
        """
        sample_size = sample_size or self.config.sample_size
        logger.info(f"åŠ è½½ {category} ç±»åˆ«æ ·æœ¬æ•°æ® (æ ·æœ¬å¤§å°: {sample_size})")
        
        # æ£€æŸ¥ç¼“å­˜
        if category in self.products_cache and category in self.reviews_cache:
            logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {category}")
            return self.products_cache[category], self.reviews_cache[category]
        
        # æ–‡ä»¶è·¯å¾„
        meta_file = Path(self.config.data_dir) / f"{category}_meta.parquet"
        reviews_file = Path(self.config.data_dir) / f"{category}_reviews.parquet"
        
        if not meta_file.exists() or not reviews_file.exists():
            logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {category}")
            return None, None
            
        try:
            # åŠ è½½å’Œé‡‡æ ·äº§å“æ•°æ®
            meta_df = pd.read_parquet(meta_file)
            if len(meta_df) > sample_size:
                meta_df = meta_df.sample(n=sample_size, random_state=42)
            
            # åŠ è½½ç›¸å…³è¯„è®ºæ•°æ®
            product_ids = set(meta_df['parent_asin'].tolist())
            reviews_df = pd.read_parquet(reviews_file)
            reviews_df = reviews_df[reviews_df['parent_asin'].isin(product_ids)]
            
            # é™åˆ¶è¯„è®ºæ•°æ®å¤§å°
            max_reviews = sample_size * 3
            if len(reviews_df) > max_reviews:
                reviews_df = reviews_df.sample(n=max_reviews, random_state=42)
            
            # ç¼“å­˜æ•°æ®
            self.products_cache[category] = meta_df
            self.reviews_cache[category] = reviews_df
            
            logger.info(f"æˆåŠŸåŠ è½½ {len(meta_df)} ä¸ªäº§å“å’Œ {len(reviews_df)} æ¡è¯„è®º")
            return meta_df, reviews_df
            
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®å¤±è´¥ {category}: {e}")
            return None, None
    
    def query_teacher_model(self, 
                          prompt: str, 
                          max_tokens: int = None,
                          temperature: float = None) -> str:
        """
        æŸ¥è¯¢Teacheræ¨¡å‹ (Llama3)
        
        WWW2026æŒ‡å®šï¼šä½¿ç”¨Llama3ä½œä¸ºæ€§èƒ½æœ€ä¼˜çš„Teacheræ¨¡å‹
        
        Args:
            prompt: è¾“å…¥æç¤º
            max_tokens: æœ€å¤§tokenæ•°  
            temperature: æ¸©åº¦å‚æ•°
            
        Returns:
            æ¨¡å‹å›å¤
        """
        max_tokens = max_tokens or self.config.max_tokens
        temperature = temperature or self.config.temperature
        
        try:
            payload = {
                "model": self.config.teacher_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_tokens,
                    "top_p": 0.9,
                    "repeat_penalty": 1.1
                }
            }
            
            response = requests.post(
                self.config.ollama_url, 
                json=payload, 
                timeout=self.config.timeout
            )
            response.raise_for_status()
            
            result = response.json()
            return result.get('response', '').strip()
            
        except Exception as e:
            logger.error(f"Teacheræ¨¡å‹æŸ¥è¯¢å¤±è´¥: {e}")
            return ""
    
    def compute_fisher_informed_score(self, 
                                    user_profile: str, 
                                    item: Dict, 
                                    fisher_weights: Optional[torch.Tensor] = None) -> float:
        """
        è®¡ç®—Fisherä¿¡æ¯å¢å¼ºçš„æ¨èå¾—åˆ†
        
        WWW2026åˆ›æ–°ç‚¹ï¼š
        å°†Fisheræƒé‡åº”ç”¨äºæ¨èå¾—åˆ†è®¡ç®—ï¼Œçªå‡ºé«˜å±‚è¯­ä¹‰ä¿¡æ¯çš„è´¡çŒ®
        
        Args:
            user_profile: ç”¨æˆ·ç”»åƒ
            item: å€™é€‰ç‰©å“
            fisher_weights: Fisheræƒé‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Fisherå¢å¼ºçš„æ¨èå¾—åˆ†
        """
        if not self.config.use_fisher_weighting:
            return self._compute_base_score(user_profile, item)
        
        # è·å–æˆ–è®¡ç®—Fisheræƒé‡
        if fisher_weights is None:
            fisher_weights = self._get_cached_fisher_weights()
        
        # åŸºç¡€æ¨èå¾—åˆ†
        base_score = self._compute_base_score(user_profile, item)
        
        # æå–è¯­ä¹‰å±‚ç‰¹å¾ï¼ˆæ¨¡æ‹Ÿé«˜å±‚è¯­ä¹‰åŒ¹é…ï¼‰
        semantic_features = self._extract_semantic_features(user_profile, item)
        
        # åº”ç”¨Fisheræƒé‡ï¼ˆé‡ç‚¹å¢å¼ºé«˜å±‚è¯­ä¹‰ï¼‰
        if len(fisher_weights) > 0:
            # ä½¿ç”¨é«˜å±‚æƒé‡ï¼ˆå50%å±‚ï¼‰å¢å¼ºè¯­ä¹‰å¾—åˆ†
            high_layer_weights = fisher_weights[len(fisher_weights)//2:]
            semantic_boost = high_layer_weights.mean().item() * self.config.semantic_boost
            
            # Fisherå¢å¼ºå¾—åˆ†
            fisher_score = base_score * (1.0 + semantic_boost * semantic_features)
        else:
            fisher_score = base_score
        
        return max(0.0, min(fisher_score, 1.0))  # å½’ä¸€åŒ–åˆ°[0,1]
    
    def _compute_base_score(self, user_profile: str, item: Dict) -> float:
        """è®¡ç®—åŸºç¡€æ¨èå¾—åˆ†"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºå…³é”®è¯åŒ¹é…
        item_text = f"{item.get('title', '')} {item.get('description', '')}"
        
        # æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ï¼‰
        user_words = set(user_profile.lower().split())
        item_words = set(item_text.lower().split())
        
        if len(user_words) == 0 or len(item_words) == 0:
            return 0.0
        
        overlap = len(user_words.intersection(item_words))
        similarity = overlap / (len(user_words) + len(item_words) - overlap + 1e-6)
        
        # è€ƒè™‘ç‰©å“è¯„åˆ†
        rating_boost = float(item.get('average_rating', 3.0)) / 5.0
        
        return similarity * 0.7 + rating_boost * 0.3
    
    def _extract_semantic_features(self, user_profile: str, item: Dict) -> float:
        """
        æå–è¯­ä¹‰ç‰¹å¾åŒ¹é…åº¦
        
        æ¨¡æ‹Ÿé«˜å±‚è¯­ä¹‰ç†è§£ï¼šç”¨æˆ·åå¥½ä¸ç‰©å“ç‰¹æ€§çš„æ·±å±‚åŒ¹é…
        """
        # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºæ–‡æœ¬å¤æ‚åº¦å’Œæƒ…æ„ŸåŒ¹é…
        user_complexity = len(set(user_profile.lower().split())) / max(len(user_profile.split()), 1)
        
        item_text = f"{item.get('title', '')} {item.get('description', '')}"
        item_complexity = len(set(item_text.lower().split())) / max(len(item_text.split()), 1)
        
        # è¯­ä¹‰å¤æ‚åº¦åŒ¹é…
        semantic_match = 1.0 - abs(user_complexity - item_complexity)
        
        return max(0.0, min(semantic_match, 1.0))
    
    def _get_cached_fisher_weights(self) -> torch.Tensor:
        """è·å–ç¼“å­˜çš„Fisheræƒé‡"""
        cache_key = f"fisher_weights_{self.config.teacher_model}"
        
        if cache_key not in self.fisher_weights_cache:
            # ç”Ÿæˆé»˜è®¤Fisheræƒé‡ï¼ˆåŸºäºç†è®ºå‡è®¾ï¼‰
            num_layers = 32  # Llama3å±‚æ•°
            layer_weights = []
            
            for i in range(num_layers):
                # ä¸Šå±‚æƒé‡æ›´å¤§
                depth_ratio = i / (num_layers - 1)
                weight = 0.5 + depth_ratio * 1.5  # 0.5åˆ°2.0çš„æƒé‡
                layer_weights.append(weight)
            
            self.fisher_weights_cache[cache_key] = torch.tensor(layer_weights)
        
        return self.fisher_weights_cache[cache_key]
    
    def generate_user_profile(self, user_reviews: pd.DataFrame) -> str:
        """
        åŸºäºç”¨æˆ·è¯„è®ºç”Ÿæˆç”¨æˆ·ç”»åƒ
        
        Args:
            user_reviews: ç”¨æˆ·çš„è¯„è®ºæ•°æ®
            
        Returns:
            ç”¨æˆ·ç”»åƒæè¿°
        """
        if user_reviews.empty:
            return "No previous reviews available"
        
        # æå–å…³é”®ä¿¡æ¯
        avg_rating = user_reviews['rating'].mean()
        review_count = len(user_reviews)
        recent_reviews = user_reviews.head(3)['text'].tolist()
        
        # æ„å»ºprompt
        prompt = f"""Based on the following user review history, create a brief user profile:

User Statistics:
- Average Rating: {avg_rating:.1f}/5.0
- Total Reviews: {review_count}

Recent Reviews:
{chr(10).join([f"- {review[:100]}..." for review in recent_reviews])}

Please provide a concise user profile (2-3 sentences) describing their preferences and shopping patterns:"""

        return self.query_ollama(prompt, max_tokens=150)
    
    def recommend_products(self, category: str, user_profile: str, top_k: int = 5) -> List[Dict]:
        """
        ä¸ºç”¨æˆ·æ¨èäº§å“
        
        Args:
            category: äº§å“ç±»åˆ«
            user_profile: ç”¨æˆ·ç”»åƒ
            top_k: æ¨èäº§å“æ•°é‡
            
        Returns:
            æ¨èäº§å“åˆ—è¡¨
        """
        if category not in self.products_cache:
            print(f"âŒ No data loaded for category: {category}")
            return []
        
        products_df = self.products_cache[category]
        
        # éšæœºé€‰æ‹©ä¸€äº›äº§å“ä½œä¸ºå€™é€‰
        candidate_products = products_df.sample(n=min(20, len(products_df))).to_dict('records')
        
        # æ„å»ºæ¨èprompt
        products_info = []
        for i, product in enumerate(candidate_products):
            title = str(product.get('title', 'Unknown'))[:100]
            price = product.get('price', 'N/A')
            rating = product.get('average_rating', 'N/A')
            products_info.append(f"{i+1}. {title} (Price: {price}, Rating: {rating})")
        
        prompt = f"""You are an AI shopping assistant. Based on the user profile below, recommend the top {top_k} products from the following list:

User Profile: {user_profile}

Available Products:
{chr(10).join(products_info)}

Please recommend the top {top_k} products that best match this user's preferences. 
Respond with just the product numbers (e.g., "1, 3, 7, 12, 15") and a brief explanation for each choice:"""

        response = self.query_ollama(prompt, max_tokens=300)
        
        # è§£ææ¨èç»“æœ
        recommendations = []
        try:
            # ç®€å•è§£ææ•°å­—
            import re
            numbers = re.findall(r'\b(\d+)\b', response)
            recommended_indices = [int(n) - 1 for n in numbers[:top_k] if 0 <= int(n) - 1 < len(candidate_products)]
            
            for idx in recommended_indices:
                product = candidate_products[idx]
                recommendations.append({
                    'asin': product.get('parent_asin', ''),
                    'title': product.get('title', 'Unknown'),
                    'price': product.get('price', 'N/A'),
                    'rating': product.get('average_rating', 'N/A'),
                    'explanation': f"Selected based on user profile compatibility"
                })
                
        except Exception as e:
            print(f"âš ï¸ Error parsing recommendations: {e}")
            # å›é€€åˆ°éšæœºæ¨è
            for i in range(min(top_k, len(candidate_products))):
                product = candidate_products[i]
                recommendations.append({
                    'asin': product.get('parent_asin', ''),
                    'title': product.get('title', 'Unknown'),
                    'price': product.get('price', 'N/A'),
                    'rating': product.get('average_rating', 'N/A'),
                    'explanation': "Random selection due to parsing error"
                })
        
        return recommendations
    
    def run_recommendation_demo(self, category: str = "Electronics", num_users: int = 3):
        """
        è¿è¡Œæ¨èæ¼”ç¤º
        
        Args:
            category: è¦æ¼”ç¤ºçš„äº§å“ç±»åˆ«
            num_users: æ¨¡æ‹Ÿç”¨æˆ·æ•°é‡
        """
        print(f"ğŸš€ Starting Amazon Ollama Recommendation Demo")
        print(f"ğŸ“… Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¤– Model: {self.model_name}")
        print(f"ğŸ“¦ Category: {category}")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®
        products_df, reviews_df = self.load_sample_data(category, sample_size=500)
        if products_df is None or reviews_df is None:
            print("âŒ Failed to load data")
            return
        
        # æ¨¡æ‹Ÿç”¨æˆ·æ¨è
        unique_users = reviews_df['user_id'].unique()
        selected_users = np.random.choice(unique_users, min(num_users, len(unique_users)), replace=False)
        
        results = []
        
        for i, user_id in enumerate(selected_users):
            print(f"\nğŸ‘¤ User {i+1}/{num_users} (ID: {user_id})")
            print("-" * 40)
            
            # è·å–ç”¨æˆ·å†å²è¯„è®º
            user_reviews = reviews_df[reviews_df['user_id'] == user_id]
            print(f"ğŸ“ Historical reviews: {len(user_reviews)}")
            
            # ç”Ÿæˆç”¨æˆ·ç”»åƒ
            print("ğŸ§  Generating user profile...")
            user_profile = self.generate_user_profile(user_reviews)
            print(f"ğŸ‘¤ User Profile: {user_profile}")
            
            # ç”Ÿæˆæ¨è
            print("ğŸ¯ Generating recommendations...")
            recommendations = self.recommend_products(category, user_profile, top_k=3)
            
            print(f"\nğŸ“‹ Top 3 Recommendations:")
            for j, rec in enumerate(recommendations):
                print(f"  {j+1}. {rec['title'][:80]}...")
                print(f"     Price: {rec['price']}, Rating: {rec['rating']}")
                print(f"     Reason: {rec['explanation']}")
                print()
            
            results.append({
                'user_id': user_id,
                'user_profile': user_profile,
                'recommendations': recommendations,
                'historical_reviews': len(user_reviews)
            })
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f"amazon_recommendations_{category}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… Demo completed! Results saved to {output_file}")
        print(f"ğŸ“Š Generated recommendations for {len(results)} users")
        
        return results

class Llama3Recommender(BaseRecommender):
    """
    Llama3æ¨èå™¨å®ç°
    
    WWW2026æ ¸å¿ƒï¼šåŸºäºLlama3çš„Fisherä¿¡æ¯é©±åŠ¨æ¨èç³»ç»Ÿ
    """
    
    def __init__(self, config: Optional[RecommendationConfig] = None):
        super().__init__(config)
        logger.info("Llama3æ¨èå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate_recommendations(self, 
                               user_profile: str, 
                               category: str, 
                               top_k: int = None) -> List[Dict]:
        """
        ç”ŸæˆLlama3é©±åŠ¨çš„æ¨èç»“æœ
        
        Args:
            user_profile: ç”¨æˆ·ç”»åƒ
            category: äº§å“ç±»åˆ«  
            top_k: æ¨èæ•°é‡
            
        Returns:
            æ¨èç»“æœåˆ—è¡¨
        """
        top_k = top_k or self.config.top_k
        
        # åŠ è½½å€™é€‰æ•°æ®
        products_df, _ = self.load_sample_data(category)
        if products_df is None:
            logger.error(f"æ— æ³•åŠ è½½ç±»åˆ«æ•°æ®: {category}")
            return []
        
        # é€‰æ‹©å€™é€‰ç‰©å“
        candidates = products_df.sample(
            n=min(self.config.candidate_size, len(products_df))
        ).to_dict('records')
        
        # ä½¿ç”¨Fisherå¢å¼ºå¾—åˆ†æ’åº
        scored_items = []
        for item in candidates:
            score = self.compute_fisher_informed_score(user_profile, item)
            scored_items.append((score, item))
        
        # æ’åºå¹¶é€‰æ‹©Top-K
        scored_items.sort(key=lambda x: x[0], reverse=True)
        top_items = scored_items[:top_k]
        
        # ä½¿ç”¨Llama3ç”Ÿæˆæœ€ç»ˆæ¨èè§£é‡Š
        recommendations = []
        for score, item in top_items:
            explanation = self._generate_explanation(user_profile, item, score)
            
            recommendations.append({
                'asin': item.get('parent_asin', ''),
                'title': item.get('title', 'Unknown'),
                'price': item.get('price', 'N/A'),
                'rating': item.get('average_rating', 'N/A'),
                'fisher_score': score,
                'explanation': explanation
            })
        
        return recommendations
    
    def compute_recommendation_features(self, 
                                     user_profile: str, 
                                     items: List[Dict]) -> torch.Tensor:
        """
        è®¡ç®—æ¨èç‰¹å¾å‘é‡ï¼ˆç”¨äºFisherä¿¡æ¯è®¡ç®—ï¼‰
        
        Args:
            user_profile: ç”¨æˆ·ç”»åƒ
            items: å€™é€‰ç‰©å“åˆ—è¡¨
            
        Returns:
            ç‰¹å¾å¼ é‡ [num_items, feature_dim]
        """
        features = []
        
        for item in items:
            # åŸºç¡€ç‰¹å¾
            price_feature = self._normalize_price(item.get('price', 0))
            rating_feature = float(item.get('average_rating', 3.0)) / 5.0
            
            # æ–‡æœ¬ç‰¹å¾ï¼ˆç®€åŒ–ï¼‰
            text_similarity = self._compute_base_score(user_profile, item)
            
            # è¯­ä¹‰ç‰¹å¾
            semantic_feature = self._extract_semantic_features(user_profile, item)
            
            # ç»„åˆç‰¹å¾å‘é‡
            feature_vector = [
                price_feature, 
                rating_feature, 
                text_similarity, 
                semantic_feature
            ]
            features.append(feature_vector)
        
        return torch.tensor(features, dtype=torch.float32)
    
    def _generate_explanation(self, user_profile: str, item: Dict, score: float) -> str:
        """
        ä½¿ç”¨Llama3ç”Ÿæˆæ¨èè§£é‡Š
        """
        prompt = f"""åŸºäºç”¨æˆ·ç”»åƒä¸ºæ¨èç»“æœç”Ÿæˆç®€æ´è§£é‡Šã€‚

ç”¨æˆ·ç”»åƒï¼š{user_profile[:200]}

æ¨èå•†å“ï¼š{item.get('title', 'Unknown')}
å•†å“è¯„åˆ†ï¼š{item.get('average_rating', 'N/A')}
æ¨èå¾—åˆ†ï¼š{score:.3f}

è¯·ç”¨1-2å¥è¯è§£é‡Šä¸ºä»€ä¹ˆæ¨èè¿™ä¸ªå•†å“ç»™è¯¥ç”¨æˆ·ï¼š"""

        explanation = self.query_teacher_model(prompt, max_tokens=100, temperature=0.1)
        
        if not explanation:
            return f"åŸºäºç”¨æˆ·åå¥½åŒ¹é…ï¼Œæ¨èå¾—åˆ†: {score:.3f}"
        
        return explanation[:200]  # é™åˆ¶é•¿åº¦
    
    def _normalize_price(self, price) -> float:
        """å½’ä¸€åŒ–ä»·æ ¼ç‰¹å¾"""
        try:
            if isinstance(price, str):
                # æå–æ•°å­—
                import re
                numbers = re.findall(r'\d+\.?\d*', price)
                if numbers:
                    price = float(numbers[0])
                else:
                    return 0.5  # é»˜è®¤ä¸­ç­‰ä»·æ ¼
            
            price = float(price)
            # ç®€å•å½’ä¸€åŒ–åˆ°[0,1]ï¼Œå‡è®¾ä»·æ ¼èŒƒå›´0-1000
            return min(price / 1000.0, 1.0)
        except:
            return 0.5

def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºLlama3æ¨èå™¨"""
    logger.info("ğŸ¯ Llama3 Fisherä¿¡æ¯é©±åŠ¨æ¨èç³»ç»Ÿ")
    
    # æ£€æŸ¥ollamaæœåŠ¡
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            logger.info("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
        else:
            logger.error("âŒ OllamaæœåŠ¡é”™è¯¯")
            return
    except:
        logger.error("âŒ æ— æ³•è¿æ¥OllamaæœåŠ¡ï¼Œè¯·å…ˆå¯åŠ¨ollama")
        return
    
    # åˆå§‹åŒ–Llama3æ¨èå™¨
    config = RecommendationConfig(
        teacher_model="llama3:latest",
        use_fisher_weighting=True,
        top_k=3
    )
    recommender = Llama3Recommender(config)
    
    # æ¼”ç¤ºæ¨è
    demo_user_profile = "ç”¨æˆ·å–œæ¬¢é«˜ç§‘æŠ€äº§å“ï¼Œæ³¨é‡æ€§èƒ½å’Œåˆ›æ–°ï¼Œç»å¸¸è´­ä¹°ç”µå­è®¾å¤‡ï¼Œåçˆ±çŸ¥åå“ç‰Œã€‚"
    demo_category = "Electronics"
    
    logger.info(f"æ¼”ç¤ºç”¨æˆ·ç”»åƒ: {demo_user_profile}")
    logger.info(f"æ¼”ç¤ºç±»åˆ«: {demo_category}")
    
    recommendations = recommender.generate_recommendations(
        user_profile=demo_user_profile,
        category=demo_category,
        top_k=3
    )
    
    if recommendations:
        logger.info("ğŸ‰ æ¨èç»“æœç”ŸæˆæˆåŠŸ!")
        for i, rec in enumerate(recommendations, 1):
            logger.info(f"{i}. {rec['title'][:50]}...")
            logger.info(f"   Fisherå¾—åˆ†: {rec['fisher_score']:.3f}")
            logger.info(f"   è§£é‡Š: {rec['explanation']}")
            logger.info("")
    else:
        logger.error("æ¨èç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    main()
