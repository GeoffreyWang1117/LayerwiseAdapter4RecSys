% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{zhao2023llm4rec}
W.~X. Zhao, K.~Zhou, J.~Li, T.~Tang, X.~Wang, Y.~Hou, Y.~Min, B.~Zhang,
  J.~Zhang, Z.~Dong \emph{et~al.}, ``A survey on large language models for
  recommendation,'' \emph{arXiv preprint arXiv:2305.19860}, 2023.

\bibitem{li2023llm4rec}
J.~Li, Y.~Zhang, Y.~Fan, Y.~Hou, P.~Ren, Z.~Tang, Z.~Zhang, W.~X. Zhao, and
  J.-R. Wen, ``How can recommender systems benefit from large language models:
  A survey,'' \emph{arXiv preprint arXiv:2306.05817}, 2023.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, and J.~Dean, ``Distilling the knowledge in a neural
  network,'' in \emph{NIPS Deep Learning and Representation Learning Workshop},
  2015.

\bibitem{rogers2020primer}
A.~Rogers, O.~Kovaleva, and A.~Rumshisky, ``A primer in bertology: What we know
  about how bert works,'' in \emph{Transactions of the Association for
  Computational Linguistics}, vol.~8, 2020, pp. 842--866.

\bibitem{tenney2019bert}
I.~Tenney, D.~Das, and E.~Pavlick, ``Bert rediscovers the classical nlp
  pipeline,'' in \emph{Proceedings of the 57th Annual Meeting of the
  Association for Computational Linguistics}, 2019, pp. 4593--4601.

\bibitem{zagoruyko2016attention}
S.~Zagoruyko and N.~Komodakis, ``Paying more attention to attention: Improving
  the performance of convolutional neural networks via attention transfer,'' in
  \emph{International Conference on Learning Representations}, 2017.

\bibitem{wang2020minilm}
W.~Wang, F.~Wei, L.~Dong, H.~Bao, N.~Yang, and M.~Zhou, ``Minilm: Deep
  self-attention distillation for task-agnostic compression of pre-trained
  transformers,'' in \emph{Advances in Neural Information Processing Systems},
  vol.~33, 2020, pp. 5776--5788.

\bibitem{romero2014fitnets}
A.~Romero, N.~Ballas, S.~E. Kahou, A.~Chassang, C.~Gatta, and Y.~Bengio,
  ``Fitnets: Hints for thin deep nets,'' in \emph{International Conference on
  Learning Representations}, 2015.

\bibitem{passban2021alp}
P.~Passban, Y.~Wu, M.~Rezagholizadeh, and Q.~Liu, ``Alp-kd: Attention-based
  layer projection for knowledge distillation,'' in \emph{Proceedings of the
  AAAI Conference on Artificial Intelligence}, vol.~35, no.~3, 2021, pp.
  2643--2651.

\bibitem{sun2019patient}
S.~Sun, Y.~Cheng, Z.~Gan, and J.~Liu, ``Patient knowledge distillation for bert
  model compression,'' in \emph{Proceedings of the 2019 Conference on Empirical
  Methods in Natural Language Processing}, 2019, pp. 4323--4332.

\bibitem{jiao2019tinybert}
X.~Jiao, Y.~Yin, L.~Shang, X.~Jiang, X.~Chen, L.~Li, F.~Wang, and Q.~Liu,
  ``Tinybert: Distilling bert for natural language understanding,'' in
  \emph{Findings of the Association for Computational Linguistics: EMNLP 2020},
  2020, pp. 4163--4174.

\bibitem{kirkpatrick2017overcoming}
J.~Kirkpatrick, R.~Pascanu, N.~Rabinowitz, J.~Veness, G.~Desjardins, A.~A.
  Rusu, K.~Milan, J.~Quan, T.~Ramalho, A.~Grabska-Barwinska \emph{et~al.},
  ``Overcoming catastrophic forgetting in neural networks,'' in
  \emph{Proceedings of the national academy of sciences}, vol. 114, no.~13,
  2017, pp. 3521--3526.

\bibitem{lee2018snip}
N.~Lee, T.~Ajanthan, and P.~H. Torr, ``Snip: Single-shot network pruning based
  on connection sensitivity,'' in \emph{International Conference on Learning
  Representations}, 2019.

\bibitem{wang2020picking}
C.~Wang, G.~Zhang, and R.~Grosse, ``Picking winning tickets before training by
  preserving gradient flow,'' in \emph{International Conference on Learning
  Representations}, 2020.

\bibitem{turner2019blockwise}
M.~A. Turner, M.~Wortsman, T.~Dettmers, and L.~Schmidt, ``Blockwise parallel
  decoding for deep autoregressive models,'' in \emph{Advances in Neural
  Information Processing Systems}, vol.~32, 2019.

\bibitem{hou2022towards}
Y.~Hou, S.~Mu, W.~X. Zhao, Y.~Li, B.~Ding, and J.-R. Wen, ``Towards universal
  sequence representation learning for recommender systems,'' in
  \emph{Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery
  and Data Mining}, 2022, pp. 585--593.

\bibitem{zhang2021neural}
S.~Zhang, L.~Yao, A.~Sun, and Y.~Tay, ``Neural collaborative filtering with
  text feature enhancement for recommendation,'' \emph{IEEE Transactions on
  Knowledge and Data Engineering}, vol.~33, no.~6, pp. 2582--2596, 2019.

\bibitem{li2023chatgpt}
J.~Li, J.~Zhang, L.~Chen, and Y.~Wang, ``Is chatgpt a good recommender? a
  preliminary study,'' in \emph{Proceedings of the 17th ACM Conference on
  Recommender Systems}, 2023, pp. 392--399.

\bibitem{dai2023uncovering}
S.~Dai, N.~Shao, H.~Zhao, W.~Yu, Z.~Si, C.~Xu, Z.~Sun, X.~Zhang, and J.~Xu,
  ``Uncovering chatgpt's capabilities in recommender systems,''
  \emph{Proceedings of the 17th ACM Conference on Recommender Systems}, pp.
  1--12, 2023.

\bibitem{geng2022recommendation}
S.~Geng, S.~Liu, Z.~Fu, Y.~Ge, and Y.~Zhang, ``Recommendation as language
  processing (rlp): A unified pretrain, personalized prompt \& predict paradigm
  (p5),'' in \emph{Proceedings of the 16th ACM Conference on Recommender
  Systems}, 2022, pp. 299--315.

\bibitem{bao2023tallrec}
K.~Bao, J.~Zhang, Y.~Zhang, W.~Wang, F.~Feng, and X.~He, ``Tallrec: An
  effective and efficient tuning framework to align large language model with
  recommendation,'' in \emph{Proceedings of the 17th ACM Conference on
  Recommender Systems}, 2023, pp. 1007--1014.

\bibitem{hou2024bridging}
Y.~Hou, J.~Li, Z.~He, A.~Yan, X.~Ren, R.~Tang, and J.-R. Wen, ``Bridging
  language and items for retrieval and recommendation,'' \emph{arXiv preprint
  arXiv:2403.03952}, 2024.

\bibitem{harper2015movielens}
F.~M. Harper and J.~A. Konstan, ``The movielens datasets: History and
  context,'' in \emph{ACM Transactions on Interactive Intelligent Systems},
  vol.~5, no.~4, 2015, pp. 1--19.

\end{thebibliography}
