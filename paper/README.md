# Layerwise Knowledge Distillation Paper

## Paper Information
- **Title**: Layerwise Knowledge Distillation for LLM-based Recommender Systems: A Fisher Information Matrix Approach
- **Author**: Zhaohui Wang (USC Viterbi School of Engineering)
- **Email**: zwang000@usc.edu
- **Conference**: WWW2026 submission
- **Pages**: 11 pages
- **Format**: IEEE Conference format

## File Structure

### Main Files
- `www2026_paper_enhanced.tex` - Main LaTeX paper (58KB)
- `www2026_paper_enhanced.pdf` - Compiled PDF (2.3MB)
- `references.bib` - Bibliography (11KB)

### Figures (PNG format, 5 files)
- `fisher_heatmap_enhanced.png` - Fisher Information heatmap (541KB)
- `semantic_emphasis_analysis.png` - Semantic emphasis analysis (438KB)  
- `training_curves.png` - Training stability curves (612KB)
- `performance_comparison.png` - Performance comparison (535KB)
- `layer_importance_evolution.png` - Layer importance evolution (410KB)

### Tables (LaTeX format, 5 files)
- `main_results.tex` - Main experimental results
- `ablation_study.tex` - Ablation study results
- `cross_domain.tex` - Cross-domain validation
- `fisher_statistics.tex` - Fisher information statistics
- `all_tables.tex` - Combined tables file

## Compilation
```bash
pdflatex www2026_paper_enhanced.tex
```

## Key Features
- 11 pages of comprehensive content
- 5 high-quality figures (PNG format for compatibility)
- 25+ citations with complete bibliography
- Theoretical analysis with Fisher Information Matrix
- Large-scale experimental validation
- Industrial deployment considerations

## Total Size: 4.9MB
