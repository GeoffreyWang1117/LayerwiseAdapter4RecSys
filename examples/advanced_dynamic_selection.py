#!/usr/bin/env python3
"""
é«˜çº§åŠ¨æ€å±‚é€‰æ‹©å®ç° - åŸºäºæœºå™¨å­¦ä¹ çš„æ™ºèƒ½å±‚é€‰æ‹©å™¨
åŒ…å«å­¦ä¹ å‹å¤æ‚åº¦åˆ†æå’Œé¢„æµ‹æ€§å±‚é€‰æ‹©
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, field
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import pickle

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AdvancedLayerConfig:
    """é«˜çº§åŠ¨æ€å±‚é€‰æ‹©é…ç½®"""
    max_layers: int = 32
    min_layers: int = 4
    layer_options: List[int] = field(default_factory=lambda: [4, 8, 12, 16, 20, 24, 32])
    
    # å­¦ä¹ å‹å‚æ•°
    learning_enabled: bool = True
    min_samples_for_learning: int = 100
    retrain_interval: int = 1000  # æ¯1000æ¬¡æ¨ç†é‡æ–°è®­ç»ƒ
    
    # æ€§èƒ½ç›®æ ‡
    latency_budget_ms: float = 100.0
    memory_budget_mb: float = 500.0
    quality_threshold: float = 0.85
    
    # ç‰¹å¾æƒé‡
    feature_weights: Dict[str, float] = field(default_factory=lambda: {
        'query_complexity': 0.3,
        'user_history': 0.2,
        'category_difficulty': 0.2,
        'resource_constraint': 0.2,
        'quality_requirement': 0.1
    })

class SmartComplexityAnalyzer:
    """æ™ºèƒ½å¤æ‚åº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.category_complexity_map = {
            'Electronics': 0.8,
            'Books': 0.6,
            'Clothing': 0.7,
            'Home': 0.5,
            'Sports': 0.6,
            'all': 0.7
        }
        
        self.user_interaction_history = {}  # ç”¨æˆ·äº¤äº’å†å²
        self.category_performance_history = {}  # ç±»åˆ«æ€§èƒ½å†å²
        
    def analyze_query_complexity(self, query: str, user_id: str, category: str) -> Dict[str, float]:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦ - è¿”å›å¤šç»´å¤æ‚åº¦ç‰¹å¾"""
        
        # 1. æ–‡æœ¬å¤æ‚åº¦
        words = query.lower().split()
        text_complexity = {
            'length': min(1.0, len(words) / 20),  # æ–‡æœ¬é•¿åº¦
            'vocabulary_diversity': len(set(words)) / len(words) if words else 0,  # è¯æ±‡å¤šæ ·æ€§
            'semantic_density': self._calculate_semantic_density(words),  # è¯­ä¹‰å¯†åº¦
            'query_specificity': self._calculate_query_specificity(words)  # æŸ¥è¯¢å…·ä½“æ€§
        }
        
        # 2. ç”¨æˆ·å†å²å¤æ‚åº¦
        user_complexity = self._analyze_user_history_complexity(user_id)
        
        # 3. ç±»åˆ«å¤æ‚åº¦
        category_complexity = {
            'base_difficulty': self.category_complexity_map.get(category, 0.5),
            'historical_performance': self._get_category_historical_complexity(category)
        }
        
        # 4. ç»¼åˆå¤æ‚åº¦è¯„åˆ†
        overall_complexity = (
            np.mean(list(text_complexity.values())) * 0.4 +
            user_complexity * 0.3 +
            np.mean(list(category_complexity.values())) * 0.3
        )
        
        return {
            'text_complexity': text_complexity,
            'user_complexity': user_complexity,
            'category_complexity': category_complexity,
            'overall_complexity': min(1.0, max(0.1, overall_complexity))
        }
        
    def _calculate_semantic_density(self, words: List[str]) -> float:
        """è®¡ç®—è¯­ä¹‰å¯†åº¦"""
        if not words:
            return 0.0
            
        # ç®€åŒ–çš„è¯­ä¹‰å¯†åº¦è®¡ç®— - åŸºäºè¯æ±‡é‡è¦æ€§
        important_words = ['é«˜ç«¯', 'ä¸“ä¸š', 'å®šåˆ¶', 'æ™ºèƒ½', 'å…¨æ–¹ä½', 'æ‰¹é‡', 'ä¼ä¸šçº§']
        semantic_score = sum(1 for word in words if any(imp in word for imp in important_words))
        
        return min(1.0, semantic_score / len(words))
        
    def _calculate_query_specificity(self, words: List[str]) -> float:
        """è®¡ç®—æŸ¥è¯¢å…·ä½“æ€§"""
        if not words:
            return 0.0
            
        # å…·ä½“æ€§æŒ‡æ ‡ - åŸºäºä¿®é¥°è¯å’Œé™å®šè¯
        specific_indicators = ['å‹å·', 'å“ç‰Œ', 'è§„æ ¼', 'é…ç½®', 'é¢œè‰²', 'å°ºå¯¸', 'æè´¨']
        specificity_score = sum(1 for word in words if any(spec in word for spec in specific_indicators))
        
        return min(1.0, specificity_score / max(1, len(words) - 2))  # æ’é™¤å¸¸è§åŠŸèƒ½è¯
        
    def _analyze_user_history_complexity(self, user_id: str) -> float:
        """åˆ†æç”¨æˆ·å†å²å¤æ‚åº¦"""
        if user_id not in self.user_interaction_history:
            return 0.5  # æ–°ç”¨æˆ·é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
            
        history = self.user_interaction_history[user_id]
        return np.mean(history.get('complexity_scores', [0.5]))
        
    def _get_category_historical_complexity(self, category: str) -> float:
        """è·å–ç±»åˆ«å†å²å¤æ‚åº¦"""
        if category not in self.category_performance_history:
            return 0.5
            
        history = self.category_performance_history[category]
        return np.mean(history.get('avg_complexity', [0.5]))
        
    def update_user_history(self, user_id: str, complexity_score: float, performance: float):
        """æ›´æ–°ç”¨æˆ·å†å²è®°å½•"""
        if user_id not in self.user_interaction_history:
            self.user_interaction_history[user_id] = {
                'complexity_scores': [],
                'performance_scores': [],
                'interaction_count': 0
            }
            
        history = self.user_interaction_history[user_id]
        history['complexity_scores'].append(complexity_score)
        history['performance_scores'].append(performance)
        history['interaction_count'] += 1
        
        # ä¿æŒå†å²è®°å½•å¤§å°
        if len(history['complexity_scores']) > 50:
            history['complexity_scores'] = history['complexity_scores'][-50:]
            history['performance_scores'] = history['performance_scores'][-50:]
            
    def update_category_history(self, category: str, complexity_score: float, performance: float):
        """æ›´æ–°ç±»åˆ«å†å²è®°å½•"""
        if category not in self.category_performance_history:
            self.category_performance_history[category] = {
                'avg_complexity': [],
                'avg_performance': [],
                'sample_count': 0
            }
            
        history = self.category_performance_history[category]
        history['avg_complexity'].append(complexity_score)
        history['avg_performance'].append(performance)
        history['sample_count'] += 1
        
        # ä¿æŒå†å²è®°å½•å¤§å°
        if len(history['avg_complexity']) > 100:
            history['avg_complexity'] = history['avg_complexity'][-100:]
            history['avg_performance'] = history['avg_performance'][-100:]

class PredictiveLayerSelector:
    """é¢„æµ‹æ€§å±‚é€‰æ‹©å™¨"""
    
    def __init__(self, config: AdvancedLayerConfig):
        self.config = config
        self.complexity_analyzer = SmartComplexityAnalyzer()
        
        # æœºå™¨å­¦ä¹ æ¨¡å‹
        self.layer_predictor = None  # å±‚æ•°é¢„æµ‹æ¨¡å‹
        self.performance_predictor = None  # æ€§èƒ½é¢„æµ‹æ¨¡å‹
        self.scaler = StandardScaler()
        
        # è®­ç»ƒæ•°æ®æ”¶é›†
        self.training_data = []
        self.is_trained = False
        self.inference_count = 0
        
        # æ€§èƒ½å†å²
        self.performance_history = {
            layer: {'latency': [], 'memory': [], 'quality': []}
            for layer in self.config.layer_options
        }
        
        logger.info("ğŸ§  åˆå§‹åŒ–é¢„æµ‹æ€§å±‚é€‰æ‹©å™¨")
        
    def select_optimal_layers(self, query: str, user_id: str, category: str,
                            device_type: str = 'cloud', performance_mode: str = 'balanced') -> Dict[str, Any]:
        """é€‰æ‹©æœ€ä¼˜å±‚æ•° - ä½¿ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹"""
        
        # 1. åˆ†æå¤æ‚åº¦ç‰¹å¾
        complexity_analysis = self.complexity_analyzer.analyze_query_complexity(query, user_id, category)
        
        # 2. æå–ç‰¹å¾å‘é‡
        features = self._extract_features(complexity_analysis, device_type, performance_mode)
        
        # 3. é¢„æµ‹æœ€ä¼˜å±‚æ•°
        if self.is_trained and self.layer_predictor is not None:
            predicted_layers = self._predict_optimal_layers(features)
        else:
            predicted_layers = self._fallback_layer_selection(complexity_analysis, device_type)
            
        # 4. éªŒè¯å’Œè°ƒæ•´
        final_layers = self._validate_and_adjust_layers(predicted_layers, device_type, performance_mode)
        
        # 5. é¢„æµ‹æ€§èƒ½æŒ‡æ ‡
        predicted_performance = self._predict_performance_metrics(final_layers, features)
        
        selection_result = {
            'selected_layers': final_layers,
            'complexity_analysis': complexity_analysis,
            'features': features,
            'predicted_performance': predicted_performance,
            'selection_confidence': self._calculate_selection_confidence(features, final_layers)
        }
        
        self.inference_count += 1
        return selection_result
        
    def _extract_features(self, complexity_analysis: Dict, device_type: str, performance_mode: str) -> np.ndarray:
        """æå–ç‰¹å¾å‘é‡"""
        features = []
        
        # å¤æ‚åº¦ç‰¹å¾
        text_comp = complexity_analysis['text_complexity']
        features.extend([
            text_comp['length'],
            text_comp['vocabulary_diversity'],
            text_comp['semantic_density'],
            text_comp['query_specificity']
        ])
        
        # ç”¨æˆ·å’Œç±»åˆ«ç‰¹å¾
        features.append(complexity_analysis['user_complexity'])
        features.extend(list(complexity_analysis['category_complexity'].values()))
        
        # è®¾å¤‡å’Œæ€§èƒ½æ¨¡å¼ç‰¹å¾ (one-hotç¼–ç )
        device_features = [0, 0, 0]  # mobile, edge, cloud
        device_idx = {'mobile': 0, 'edge': 1, 'cloud': 2}.get(device_type, 2)
        device_features[device_idx] = 1
        features.extend(device_features)
        
        mode_features = [0, 0, 0]  # fast, balanced, accurate
        mode_idx = {'fast': 0, 'balanced': 1, 'accurate': 2}.get(performance_mode, 1)
        mode_features[mode_idx] = 1
        features.extend(mode_features)
        
        return np.array(features)
        
    def _predict_optimal_layers(self, features: np.ndarray) -> int:
        """ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹æœ€ä¼˜å±‚æ•°"""
        try:
            # æ ‡å‡†åŒ–ç‰¹å¾
            features_scaled = self.scaler.transform(features.reshape(1, -1))
            
            # é¢„æµ‹å±‚æ•°
            predicted_layers_continuous = self.layer_predictor.predict(features_scaled)[0]
            
            # æ˜ å°„åˆ°å¯ç”¨çš„å±‚æ•°é€‰é¡¹
            predicted_layers = min(self.config.layer_options, 
                                 key=lambda x: abs(x - predicted_layers_continuous))
            
            return predicted_layers
            
        except Exception as e:
            logger.warning(f"é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥: {e}")
            return self._fallback_layer_selection({'overall_complexity': 0.5}, 'cloud')
            
    def _fallback_layer_selection(self, complexity_analysis: Dict, device_type: str) -> int:
        """å›é€€å±‚é€‰æ‹©ç­–ç•¥"""
        complexity = complexity_analysis.get('overall_complexity', 0.5)
        
        if device_type == 'mobile':
            return 4 if complexity < 0.6 else 8
        elif device_type == 'edge':
            return 8 if complexity < 0.7 else 12
        else:  # cloud
            if complexity < 0.4:
                return 8
            elif complexity < 0.7:
                return 12
            else:
                return 16
                
    def _validate_and_adjust_layers(self, predicted_layers: int, device_type: str, performance_mode: str) -> int:
        """éªŒè¯å’Œè°ƒæ•´å±‚æ•°é€‰æ‹©"""
        # è®¾å¤‡çº¦æŸ
        device_max_layers = {'mobile': 8, 'edge': 16, 'cloud': 32}
        max_allowed = device_max_layers.get(device_type, 32)
        
        # æ€§èƒ½æ¨¡å¼è°ƒæ•´
        if performance_mode == 'fast':
            max_allowed = min(max_allowed, 12)
        elif performance_mode == 'accurate':
            # ç²¾ç¡®æ¨¡å¼å…è®¸æ›´å¤šå±‚æ•°ï¼Œä½†ä»éœ€ç¬¦åˆè®¾å¤‡çº¦æŸ
            pass
            
        # ç¡®ä¿åœ¨å¯ç”¨é€‰é¡¹å†…
        validated_layers = min(predicted_layers, max_allowed)
        validated_layers = max(validated_layers, self.config.min_layers)
        
        # æ˜ å°„åˆ°æœ€è¿‘çš„å¯ç”¨å±‚æ•°
        final_layers = min(self.config.layer_options, 
                          key=lambda x: abs(x - validated_layers))
        
        return final_layers
        
    def _predict_performance_metrics(self, layers: int, features: np.ndarray) -> Dict[str, float]:
        """é¢„æµ‹æ€§èƒ½æŒ‡æ ‡"""
        if layers in self.performance_history:
            history = self.performance_history[layers]
            
            return {
                'expected_latency_ms': np.mean(history['latency']) if history['latency'] else layers * 8.0,
                'expected_memory_mb': np.mean(history['memory']) if history['memory'] else layers * 12.5,
                'expected_quality': np.mean(history['quality']) if history['quality'] else self._estimate_quality_by_layers(layers)
            }
        else:
            return {
                'expected_latency_ms': layers * 8.0,
                'expected_memory_mb': layers * 12.5,
                'expected_quality': self._estimate_quality_by_layers(layers)
            }
            
    def _estimate_quality_by_layers(self, layers: int) -> float:
        """åŸºäºå±‚æ•°ä¼°ç®—è´¨é‡"""
        quality_map = {4: 0.85, 8: 0.92, 12: 1.0, 16: 1.0, 20: 0.95, 24: 0.90, 32: 0.85}
        return quality_map.get(layers, 0.9)
        
    def _calculate_selection_confidence(self, features: np.ndarray, selected_layers: int) -> float:
        """è®¡ç®—é€‰æ‹©ç½®ä¿¡åº¦"""
        if not self.is_trained:
            return 0.5
            
        # åŸºäºå†å²æ•°æ®çš„ç½®ä¿¡åº¦è®¡ç®—
        base_confidence = 0.7
        
        # å¦‚æœæœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œæé«˜ç½®ä¿¡åº¦
        if len(self.training_data) > self.config.min_samples_for_learning:
            base_confidence = 0.85
            
        return base_confidence
        
    def record_performance(self, layers: int, latency_ms: float, memory_mb: float, quality: float,
                          complexity_analysis: Dict, user_id: str, category: str):
        """è®°å½•æ€§èƒ½æ•°æ®ç”¨äºå­¦ä¹ """
        
        # æ›´æ–°æ€§èƒ½å†å²
        if layers in self.performance_history:
            history = self.performance_history[layers]
            history['latency'].append(latency_ms)
            history['memory'].append(memory_mb)
            history['quality'].append(quality)
            
            # ä¿æŒå†å²è®°å½•å¤§å°
            for metric in ['latency', 'memory', 'quality']:
                if len(history[metric]) > 200:
                    history[metric] = history[metric][-200:]
        
        # æ”¶é›†è®­ç»ƒæ•°æ®
        features = self._extract_features(complexity_analysis, 'cloud', 'balanced')  # ç®€åŒ–
        self.training_data.append({
            'features': features,
            'optimal_layers': layers,
            'latency': latency_ms,
            'memory': memory_mb,
            'quality': quality
        })
        
        # æ›´æ–°å¤æ‚åº¦åˆ†æå™¨çš„å†å²è®°å½•
        overall_complexity = complexity_analysis.get('overall_complexity', 0.5)
        self.complexity_analyzer.update_user_history(user_id, overall_complexity, quality)
        self.complexity_analyzer.update_category_history(category, overall_complexity, quality)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ
        if (len(self.training_data) >= self.config.min_samples_for_learning and 
            self.inference_count % self.config.retrain_interval == 0):
            self._retrain_models()
            
    def _retrain_models(self):
        """é‡æ–°è®­ç»ƒæ¨¡å‹"""
        if len(self.training_data) < self.config.min_samples_for_learning:
            return
            
        logger.info(f"ğŸ”„ é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒæ ·æœ¬æ•°: {len(self.training_data)}")
        
        try:
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X = np.array([data['features'] for data in self.training_data])
            y_layers = np.array([data['optimal_layers'] for data in self.training_data])
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            X_scaled = self.scaler.fit_transform(X)
            
            # è®­ç»ƒå±‚æ•°é¢„æµ‹æ¨¡å‹
            self.layer_predictor = RandomForestRegressor(
                n_estimators=100, 
                random_state=42,
                max_depth=10
            )
            self.layer_predictor.fit(X_scaled, y_layers)
            
            # è®­ç»ƒæ€§èƒ½é¢„æµ‹æ¨¡å‹
            y_quality = np.array([data['quality'] for data in self.training_data])
            self.performance_predictor = LinearRegression()
            self.performance_predictor.fit(X_scaled, y_quality)
            
            self.is_trained = True
            logger.info("âœ… æ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'layer_predictor': self.layer_predictor,
            'performance_predictor': self.performance_predictor,
            'scaler': self.scaler,
            'training_data': self.training_data,
            'performance_history': self.performance_history,
            'is_trained': self.is_trained
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
            
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {filepath}")
        
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
                
            self.layer_predictor = model_data['layer_predictor']
            self.performance_predictor = model_data['performance_predictor']
            self.scaler = model_data['scaler']
            self.training_data = model_data['training_data']
            self.performance_history = model_data['performance_history']
            self.is_trained = model_data['is_trained']
            
            logger.info(f"ğŸ“ æ¨¡å‹å·²ä» {filepath} åŠ è½½")
            
        except Exception as e:
            logger.warning(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

class AdvancedDynamicRecommendationSystem:
    """é«˜çº§åŠ¨æ€æ¨èç³»ç»Ÿ"""
    
    def __init__(self, config: AdvancedLayerConfig = None):
        self.config = config or AdvancedLayerConfig()
        self.layer_selector = PredictiveLayerSelector(self.config)
        
        # æ¨¡æ‹Ÿæ•°æ®
        self.item_catalog = self._create_mock_item_catalog()
        self.user_features = self._create_mock_user_features()
        self.item_features = self._create_mock_item_features()
        
        logger.info("ğŸš€ é«˜çº§åŠ¨æ€æ¨èç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
    def _create_mock_item_catalog(self) -> Dict[str, Dict]:
        """åˆ›å»ºæ¨¡æ‹Ÿç‰©å“ç›®å½•"""
        categories = ['Electronics', 'Books', 'Clothing', 'Home', 'Sports']
        items = {}
        
        for i in range(2000):
            item_id = f"item_{i:04d}"
            items[item_id] = {
                'title': f"Product {i}",
                'category': np.random.choice(categories),
                'price': np.random.uniform(10, 1000),
                'rating': np.random.uniform(3.0, 5.0),
                'popularity': np.random.exponential(100),
                'complexity_score': np.random.uniform(0.3, 0.9)
            }
            
        return items
        
    def _create_mock_user_features(self) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºæ¨¡æ‹Ÿç”¨æˆ·ç‰¹å¾"""
        users = {}
        for i in range(200):
            user_id = f"user_{i:03d}"
            users[user_id] = torch.randn(128)  # æ›´é«˜ç»´ç‰¹å¾
        return users
        
    def _create_mock_item_features(self) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºæ¨¡æ‹Ÿç‰©å“ç‰¹å¾"""
        items = {}
        for item_id in self.item_catalog.keys():
            items[item_id] = torch.randn(128)  # æ›´é«˜ç»´ç‰¹å¾
        return items
        
    def recommend(self, query: str, user_id: str, category: str = 'all',
                 device_type: str = 'cloud', performance_mode: str = 'balanced',
                 top_k: int = 10) -> Dict[str, Any]:
        """æ‰§è¡Œé«˜çº§åŠ¨æ€æ¨è"""
        
        # 1. é€‰æ‹©æœ€ä¼˜å±‚æ•°
        selection_result = self.layer_selector.select_optimal_layers(
            query, user_id, category, device_type, performance_mode
        )
        
        selected_layers = selection_result['selected_layers']
        predicted_performance = selection_result['predicted_performance']
        
        logger.info(f"ğŸ¯ ç”¨æˆ· {user_id} æŸ¥è¯¢: '{query[:30]}...'")
        logger.info(f"  ğŸ—ï¸ é€‰æ‹©å±‚æ•°: {selected_layers}")
        logger.info(f"  ğŸ“Š æ•´ä½“å¤æ‚åº¦: {selection_result['complexity_analysis']['overall_complexity']:.3f}")
        logger.info(f"  ğŸ”® é¢„æœŸæ€§èƒ½: å»¶è¿Ÿ {predicted_performance['expected_latency_ms']:.1f}ms, "
                   f"è´¨é‡ {predicted_performance['expected_quality']:.3f}")
        
        # 2. é€‰æ‹©å€™é€‰ç‰©å“
        candidate_items = self._select_advanced_candidates(query, category, user_id, top_k * 10)
        
        # 3. æ‰§è¡Œæ¨ç†
        start_time = pd.Timestamp.now()
        scores, actual_latency, actual_memory = self._simulate_advanced_inference(
            user_id, candidate_items, selected_layers
        )
        inference_time = (pd.Timestamp.now() - start_time).total_seconds() * 1000
        
        # 4. æ’åºå’Œé€‰æ‹©
        item_scores = list(zip(candidate_items, scores))
        item_scores.sort(key=lambda x: x[1], reverse=True)
        
        top_items = [item for item, score in item_scores[:top_k]]
        top_scores = [score for item, score in item_scores[:top_k]]
        
        # 5. è®¡ç®—å®é™…è´¨é‡
        actual_quality = np.mean(top_scores) * self._get_layer_quality_factor(selected_layers)
        
        # 6. è®°å½•æ€§èƒ½æ•°æ®ç”¨äºå­¦ä¹ 
        self.layer_selector.record_performance(
            selected_layers, inference_time, actual_memory, actual_quality,
            selection_result['complexity_analysis'], user_id, category
        )
        
        return {
            'items': top_items,
            'scores': top_scores,
            'selected_layers': selected_layers,
            'inference_time_ms': inference_time,
            'memory_usage_mb': actual_memory,
            'actual_quality': actual_quality,
            'selection_analysis': selection_result,
            'predicted_vs_actual': {
                'predicted_latency': predicted_performance['expected_latency_ms'],
                'actual_latency': inference_time,
                'predicted_quality': predicted_performance['expected_quality'],
                'actual_quality': actual_quality
            }
        }
        
    def _select_advanced_candidates(self, query: str, category: str, user_id: str, num_candidates: int) -> List[str]:
        """é«˜çº§å€™é€‰ç‰©å“é€‰æ‹©"""
        # åŸºäºæŸ¥è¯¢å’Œç±»åˆ«ç­›é€‰
        if category != 'all':
            candidates = [
                item_id for item_id, item_info in self.item_catalog.items()
                if item_info['category'].lower() == category.lower()
            ]
        else:
            candidates = list(self.item_catalog.keys())
        
        # åŸºäºæŸ¥è¯¢å¤æ‚åº¦ä¼˜å…ˆé€‰æ‹©
        query_words = set(query.lower().split())
        scored_candidates = []
        
        for item_id in candidates:
            item = self.item_catalog[item_id]
            # ç®€åŒ–çš„ç›¸å…³æ€§è¯„åˆ†
            title_words = set(item['title'].lower().split())
            relevance = len(query_words.intersection(title_words)) / max(len(query_words), 1)
            
            # ç»¼åˆè¯„åˆ†ï¼šç›¸å…³æ€§ + æµè¡Œåº¦ + è¯„åˆ†
            score = relevance * 0.4 + (item['popularity'] / 500) * 0.3 + (item['rating'] / 5) * 0.3
            scored_candidates.append((item_id, score))
        
        # æ’åºå¹¶é€‰æ‹©
        scored_candidates.sort(key=lambda x: x[1], reverse=True)
        selected = [item_id for item_id, score in scored_candidates[:num_candidates]]
        
        return selected
        
    def _simulate_advanced_inference(self, user_id: str, item_ids: List[str], 
                                   num_layers: int) -> Tuple[List[float], float, float]:
        """é«˜çº§æ¨ç†æ¨¡æ‹Ÿ"""
        # è·å–ç‰¹å¾
        user_feat = self.user_features.get(user_id, torch.randn(128))
        item_feats = torch.stack([
            self.item_features.get(item_id, torch.randn(128)) 
            for item_id in item_ids
        ])
        
        # æ›´å¤æ‚çš„ç›¸ä¼¼åº¦è®¡ç®—
        similarities = torch.cosine_similarity(user_feat.unsqueeze(0), item_feats, dim=1)
        
        # æ·»åŠ åŸºäºç‰©å“å¤æ‚åº¦çš„è°ƒæ•´
        complexity_adjustments = [
            self.item_catalog.get(item_id, {}).get('complexity_score', 0.5)
            for item_id in item_ids
        ]
        
        adjusted_scores = similarities + torch.tensor(complexity_adjustments) * 0.1
        scores = adjusted_scores.tolist()
        
        # å±‚æ•°å¯¹æ€§èƒ½çš„å½±å“
        layer_performance_factor = self._get_layer_quality_factor(num_layers)
        scores = [s * layer_performance_factor for s in scores]
        
        # æ¨¡æ‹Ÿå»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨
        base_latency = len(item_ids) * 0.1  # åŸºç¡€å»¶è¿Ÿ
        layer_latency = num_layers * 1.5    # å±‚çº§å»¶è¿Ÿ
        total_latency = base_latency + layer_latency + np.random.normal(0, 2)  # æ·»åŠ å™ªå£°
        
        memory_usage = num_layers * 15.0 + np.random.normal(0, 5)  # å†…å­˜ä½¿ç”¨
        
        return scores, max(1, total_latency), max(10, memory_usage)
        
    def _get_layer_quality_factor(self, num_layers: int) -> float:
        """è·å–å±‚æ•°è´¨é‡å› å­"""
        return {4: 0.85, 8: 0.92, 12: 1.0, 16: 1.0, 20: 0.95, 24: 0.90, 32: 0.85}.get(num_layers, 0.9)

def run_advanced_demo():
    """è¿è¡Œé«˜çº§åŠ¨æ€å±‚é€‰æ‹©æ¼”ç¤º"""
    logger.info("ğŸ¬ å¼€å§‹é«˜çº§åŠ¨æ€å±‚é€‰æ‹©æ¼”ç¤º...")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    config = AdvancedLayerConfig(learning_enabled=True)
    recommender = AdvancedDynamicRecommendationSystem(config)
    
    # åˆ›å»ºæ›´å¤æ‚çš„æµ‹è¯•åœºæ™¯
    test_scenarios = [
        ("é«˜ç«¯æ¸¸æˆç¬”è®°æœ¬ç”µè„‘RTX4090é…ç½®æ¨è", "user_001", "Electronics", "cloud", "accurate"),
        ("è½»è–„åŠå…¬ç¬”è®°æœ¬", "user_002", "Electronics", "mobile", "fast"),
        ("ä¸“ä¸šæ‘„å½±å™¨æå…¨å¥—é…ç½®", "user_003", "Electronics", "cloud", "accurate"),
        ("å„¿ç«¥å›¾ä¹¦", "user_004", "Books", "mobile", "fast"),
        ("ä¼ä¸šçº§æœè£…é‡‡è´­æ‰¹é‡å®šåˆ¶", "user_005", "Clothing", "edge", "balanced"),
        ("æ™ºèƒ½å®¶å±…å…¨å±‹è§£å†³æ–¹æ¡ˆ", "user_006", "Home", "cloud", "balanced"),
        ("ä¸“ä¸šå¥èº«å™¨æé…å¥—", "user_007", "Sports", "edge", "balanced"),
        ("ç®€å•æ—¥ç”¨å“", "user_008", "Home", "mobile", "fast"),
    ]
    
    results = []
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ”¥ æ‰§è¡Œé«˜çº§åŠ¨æ€æ¨èæµ‹è¯•")
    logger.info(f"{'='*80}")
    
    for i, (query, user_id, category, device, mode) in enumerate(test_scenarios):
        logger.info(f"\nã€æµ‹è¯• {i+1}ã€‘{device.upper()} - {mode.upper()}")
        logger.info(f"æŸ¥è¯¢: {query}")
        
        result = recommender.recommend(query, user_id, category, device, mode, top_k=5)
        results.append((query, result))
        
        # æ˜¾ç¤ºé¢„æµ‹vså®é™…å¯¹æ¯”
        pred_vs_actual = result['predicted_vs_actual']
        logger.info(f"  ğŸ“Š é¢„æµ‹vså®é™…:")
        logger.info(f"    å»¶è¿Ÿ: {pred_vs_actual['predicted_latency']:.1f}ms â†’ {pred_vs_actual['actual_latency']:.1f}ms")
        logger.info(f"    è´¨é‡: {pred_vs_actual['predicted_quality']:.3f} â†’ {pred_vs_actual['actual_quality']:.3f}")
        
    # åˆ†æå­¦ä¹ æ•ˆæœ
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ“ˆ å­¦ä¹ æ•ˆæœåˆ†æ")
    logger.info(f"{'='*80}")
    
    logger.info(f"ğŸ“š æ”¶é›†è®­ç»ƒæ ·æœ¬æ•°: {len(recommender.layer_selector.training_data)}")
    logger.info(f"ğŸ§  æ¨¡å‹è®­ç»ƒçŠ¶æ€: {'å·²è®­ç»ƒ' if recommender.layer_selector.is_trained else 'æœªè®­ç»ƒ'}")
    logger.info(f"ğŸ”„ æ¨ç†è®¡æ•°: {recommender.layer_selector.inference_count}")
    
    # ä¿å­˜æ¨¡å‹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = Path('results/advanced_dynamic_selection')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    model_file = results_dir / f'advanced_layer_selector_model_{timestamp}.pkl'
    recommender.layer_selector.save_model(str(model_file))
    
    # ä¿å­˜ç»“æœ
    demo_results = {
        'timestamp': timestamp,
        'config': {
            'learning_enabled': config.learning_enabled,
            'layer_options': config.layer_options,
            'min_samples_for_learning': config.min_samples_for_learning
        },
        'scenarios': [
            {
                'query': query,
                'result': {k: v for k, v in result.items() if k != 'selection_analysis'}  # ç®€åŒ–ä¿å­˜
            }
            for query, result in results
        ],
        'model_stats': {
            'training_samples': len(recommender.layer_selector.training_data),
            'is_trained': recommender.layer_selector.is_trained,
            'inference_count': recommender.layer_selector.inference_count
        }
    }
    
    results_file = results_dir / f'advanced_demo_results_{timestamp}.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(demo_results, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"\nâœ… é«˜çº§æ¼”ç¤ºå®Œæˆï¼")
    logger.info(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜è‡³: {model_file}")
    logger.info(f"ğŸ“Š ç»“æœå·²ä¿å­˜è‡³: {results_file}")

if __name__ == "__main__":
    run_advanced_demo()
