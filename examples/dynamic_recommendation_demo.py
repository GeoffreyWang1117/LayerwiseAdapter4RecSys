#!/usr/bin/env python3
"""
åŠ¨æ€å±‚é€‰æ‹©æ¨èç³»ç»Ÿå®æˆ˜ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…æ¨èåœºæ™¯ä¸­ä½¿ç”¨åŠ¨æ€å±‚é€‰æ‹©æœºåˆ¶
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import logging

# å¯¼å…¥æˆ‘ä»¬çš„åŠ¨æ€å±‚é€‰æ‹©æ¨¡å—
import sys
sys.path.append('.')
sys.path.append('..')

from experiments.dynamic_layer_selection import (
    DynamicLayerSelector, 
    InputComplexityAnalyzer,
    ResourceMonitor,
    DynamicLayerConfig
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class UserContext:
    """ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    user_id: str
    query: str
    category: str
    device_type: str  # 'mobile', 'edge', 'cloud'
    time_budget_ms: float = 100.0  # æ—¶é—´é¢„ç®—
    memory_budget_mb: float = 500.0  # å†…å­˜é¢„ç®—

@dataclass
class RecommendationResult:
    """æ¨èç»“æœ"""
    items: List[str]
    scores: List[float]
    selected_layers: int
    inference_time_ms: float
    memory_usage_mb: float
    complexity_score: float
    quality_estimate: float

class DynamicRecommendationSystem:
    """åŠ¨æ€å±‚é€‰æ‹©æ¨èç³»ç»Ÿ"""
    
    def __init__(self, config: DynamicLayerConfig = None):
        self.config = config or DynamicLayerConfig()
        self.layer_selector = DynamicLayerSelector(self.config)
        self.complexity_analyzer = InputComplexityAnalyzer()
        self.resource_monitor = ResourceMonitor()
        
        # æ¨¡æ‹Ÿçš„ç‰©å“åº“
        self.item_catalog = self._create_mock_item_catalog()
        
        # é¢„è®¡ç®—çš„ç”¨æˆ·-ç‰©å“ç‰¹å¾ï¼ˆå®é™…ä¸­ä»æ•°æ®åº“è·å–ï¼‰
        self.user_features = self._create_mock_user_features()
        self.item_features = self._create_mock_item_features()
        
        logger.info("ğŸš€ åŠ¨æ€æ¨èç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
    def _create_mock_item_catalog(self) -> Dict[str, Dict]:
        """åˆ›å»ºæ¨¡æ‹Ÿç‰©å“ç›®å½•"""
        categories = ['Electronics', 'Books', 'Clothing', 'Home', 'Sports']
        items = {}
        
        for i in range(1000):
            item_id = f"item_{i:04d}"
            items[item_id] = {
                'title': f"Product {i}",
                'category': np.random.choice(categories),
                'price': np.random.uniform(10, 500),
                'rating': np.random.uniform(3.0, 5.0),
                'popularity': np.random.exponential(100)
            }
            
        return items
        
    def _create_mock_user_features(self) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºæ¨¡æ‹Ÿç”¨æˆ·ç‰¹å¾"""
        users = {}
        for i in range(100):
            user_id = f"user_{i:03d}"
            # 64ç»´ç”¨æˆ·ç‰¹å¾å‘é‡
            users[user_id] = torch.randn(64)
        return users
        
    def _create_mock_item_features(self) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºæ¨¡æ‹Ÿç‰©å“ç‰¹å¾"""
        items = {}
        for item_id in self.item_catalog.keys():
            # 64ç»´ç‰©å“ç‰¹å¾å‘é‡
            items[item_id] = torch.randn(64)
        return items
        
    def analyze_query_complexity(self, query: str, category: str) -> float:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦"""
        # ç®€åŒ–çš„æŸ¥è¯¢å¤æ‚åº¦åˆ†æ
        complexity_factors = {
            'query_length': min(1.0, len(query.split()) / 10),  # æŸ¥è¯¢è¯æ•°
            'category_specificity': {
                'Electronics': 0.8,  # ç”µå­äº§å“éœ€æ±‚å¤æ‚
                'Books': 0.6,        # ä¹¦ç±éœ€æ±‚ä¸­ç­‰
                'Clothing': 0.7,     # æœè£…éœ€æ±‚è¾ƒå¤æ‚
                'Home': 0.5,         # å®¶å±…éœ€æ±‚ç®€å•
                'Sports': 0.6        # è¿åŠ¨ç”¨å“ä¸­ç­‰
            }.get(category, 0.5),
            'semantic_complexity': min(1.0, len(set(query.lower().split())) / len(query.split()) if query.split() else 0)
        }
        
        # ç»¼åˆå¤æ‚åº¦è¯„åˆ†
        overall_complexity = (
            complexity_factors['query_length'] * 0.4 +
            complexity_factors['category_specificity'] * 0.4 +
            complexity_factors['semantic_complexity'] * 0.2
        )
        
        return min(1.0, max(0.1, overall_complexity))
        
    def select_candidate_items(self, user_context: UserContext, num_candidates: int = 100) -> List[str]:
        """é€‰æ‹©å€™é€‰ç‰©å“"""
        # åŸºäºç±»åˆ«è¿‡æ»¤
        if user_context.category != 'all':
            candidates = [
                item_id for item_id, item_info in self.item_catalog.items()
                if item_info['category'].lower() == user_context.category.lower()
            ]
        else:
            candidates = list(self.item_catalog.keys())
            
        # éšæœºé€‰æ‹©å€™é€‰é¡¹ï¼ˆå®é™…ä¸­ä¼šä½¿ç”¨æ›´æ™ºèƒ½çš„ç­–ç•¥ï¼‰
        if len(candidates) > num_candidates:
            candidates = np.random.choice(candidates, num_candidates, replace=False).tolist()
            
        return candidates
        
    def simulate_model_inference(self, user_id: str, item_ids: List[str], 
                                num_layers: int) -> Tuple[List[float], float, float]:
        """æ¨¡æ‹Ÿæ¨¡å‹æ¨ç†è¿‡ç¨‹"""
        start_time = time.time()
        
        # è·å–ç”¨æˆ·å’Œç‰©å“ç‰¹å¾
        user_feat = self.user_features.get(user_id, torch.randn(64))
        item_feats = torch.stack([
            self.item_features.get(item_id, torch.randn(64)) 
            for item_id in item_ids
        ])
        
        # æ¨¡æ‹Ÿä¸åŒå±‚æ•°çš„è®¡ç®—å¤æ‚åº¦
        base_computation = len(item_ids) * 64  # åŸºç¡€è®¡ç®—é‡
        layer_computation = base_computation * num_layers * 0.1  # å±‚çº§è®¡ç®—é‡
        
        # æ¨¡æ‹Ÿè®¡ç®—å»¶è¿Ÿ
        simulated_delay = layer_computation / 1000000  # è½¬æ¢ä¸ºç§’
        time.sleep(min(0.01, simulated_delay))  # æœ€å¤šå»¶è¿Ÿ10ms
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆç®€åŒ–ï¼‰
        scores = torch.cosine_similarity(
            user_feat.unsqueeze(0), item_feats, dim=1
        ).tolist()
        
        # æ·»åŠ åŸºäºå±‚æ•°çš„æ€§èƒ½å½±å“
        layer_performance_factor = {
            4: 0.85, 8: 0.92, 12: 1.0, 16: 1.0,
            20: 0.95, 24: 0.90, 32: 0.85
        }.get(num_layers, 0.9)
        
        scores = [s * layer_performance_factor for s in scores]
        
        inference_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        memory_usage = num_layers * 12.5  # ç®€åŒ–çš„å†…å­˜ä½¿ç”¨ä¼°ç®—
        
        return scores, inference_time, memory_usage
        
    def recommend(self, user_context: UserContext, top_k: int = 10) -> RecommendationResult:
        """æ‰§è¡Œæ¨è"""
        logger.info(f"ğŸ¯ ä¸ºç”¨æˆ· {user_context.user_id} ç”Ÿæˆæ¨è...")
        
        # 1. åˆ†ææŸ¥è¯¢å¤æ‚åº¦
        complexity_score = self.analyze_query_complexity(
            user_context.query, user_context.category
        )
        logger.info(f"  ğŸ“Š æŸ¥è¯¢å¤æ‚åº¦: {complexity_score:.3f}")
        
        # 2. é€‰æ‹©æœ€ä¼˜å±‚æ•°
        resource_budget = {
            'mobile': 'mobile',
            'edge': 'edge',
            'cloud': 'cloud'
        }.get(user_context.device_type, 'cloud')
        
        selected_layers = self.layer_selector.select_optimal_layers(
            complexity_score, resource_budget, 'balanced'
        )
        logger.info(f"  ğŸ—ï¸ é€‰æ‹©å±‚æ•°: {selected_layers}")
        
        # 3. é€‰æ‹©å€™é€‰ç‰©å“
        candidate_items = self.select_candidate_items(user_context)
        logger.info(f"  ğŸ“¦ å€™é€‰ç‰©å“æ•°: {len(candidate_items)}")
        
        # 4. æ‰§è¡Œæ¨¡å‹æ¨ç†
        scores, inference_time, memory_usage = self.simulate_model_inference(
            user_context.user_id, candidate_items, selected_layers
        )
        
        # 5. æ’åºå¹¶é€‰æ‹©top-k
        item_scores = list(zip(candidate_items, scores))
        item_scores.sort(key=lambda x: x[1], reverse=True)
        
        top_items = [item for item, score in item_scores[:top_k]]
        top_scores = [score for item, score in item_scores[:top_k]]
        
        # 6. ä¼°ç®—æ¨èè´¨é‡
        quality_estimate = np.mean(top_scores) * self._get_layer_quality_factor(selected_layers)
        
        logger.info(f"  âš¡ æ¨ç†æ—¶é—´: {inference_time:.1f}ms")
        logger.info(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_usage:.1f}MB")
        logger.info(f"  ğŸ¯ è´¨é‡ä¼°ç®—: {quality_estimate:.3f}")
        
        return RecommendationResult(
            items=top_items,
            scores=top_scores,
            selected_layers=selected_layers,
            inference_time_ms=inference_time,
            memory_usage_mb=memory_usage,
            complexity_score=complexity_score,
            quality_estimate=quality_estimate
        )
        
    def _get_layer_quality_factor(self, num_layers: int) -> float:
        """è·å–å±‚æ•°å¯¹åº”çš„è´¨é‡å› å­"""
        return {
            4: 0.85, 8: 0.92, 12: 1.0, 16: 1.0,
            20: 0.95, 24: 0.90, 32: 0.85
        }.get(num_layers, 0.9)
        
    def batch_recommend(self, user_contexts: List[UserContext], 
                       top_k: int = 10) -> List[RecommendationResult]:
        """æ‰¹é‡æ¨è"""
        results = []
        total_time = 0
        total_memory = 0
        
        logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡æ¨èï¼Œç”¨æˆ·æ•°: {len(user_contexts)}")
        
        for i, context in enumerate(user_contexts):
            result = self.recommend(context, top_k)
            results.append(result)
            
            total_time += result.inference_time_ms
            total_memory += result.memory_usage_mb
            
            if (i + 1) % 10 == 0:
                avg_time = total_time / (i + 1)
                avg_memory = total_memory / (i + 1)
                logger.info(f"  ğŸ“ˆ è¿›åº¦: {i+1}/{len(user_contexts)}, "
                          f"å¹³å‡æ—¶é—´: {avg_time:.1f}ms, å¹³å‡å†…å­˜: {avg_memory:.1f}MB")
        
        return results
        
    def analyze_performance(self, results: List[RecommendationResult]) -> Dict[str, Any]:
        """åˆ†ææ¨èæ€§èƒ½"""
        layer_usage = {}
        device_performance = {'mobile': [], 'edge': [], 'cloud': []}
        
        for result in results:
            # ç»Ÿè®¡å±‚æ•°ä½¿ç”¨æƒ…å†µ
            layer_count = layer_usage.get(result.selected_layers, 0)
            layer_usage[result.selected_layers] = layer_count + 1
            
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        total_time = sum(r.inference_time_ms for r in results)
        total_memory = sum(r.memory_usage_mb for r in results)
        avg_quality = np.mean([r.quality_estimate for r in results])
        
        analysis = {
            'total_requests': len(results),
            'avg_inference_time_ms': total_time / len(results),
            'avg_memory_usage_mb': total_memory / len(results),
            'avg_quality_estimate': avg_quality,
            'layer_usage_distribution': layer_usage,
            'efficiency_metrics': {
                'total_time_saved_vs_max_layers': self._calculate_time_savings(results),
                'total_memory_saved_vs_max_layers': self._calculate_memory_savings(results),
                'quality_retention_rate': avg_quality / 1.0  # å‡è®¾1.0ä¸ºæœ€é«˜è´¨é‡
            }
        }
        
        return analysis
        
    def _calculate_time_savings(self, results: List[RecommendationResult]) -> float:
        """è®¡ç®—ç›¸å¯¹äºæœ€å¤§å±‚æ•°çš„æ—¶é—´èŠ‚çœ"""
        actual_time = sum(r.inference_time_ms for r in results)
        # å‡è®¾æœ€å¤§å±‚æ•°(16å±‚)çš„æ¨ç†æ—¶é—´æ˜¯å½“å‰çš„1.6å€
        max_layer_time = sum(r.inference_time_ms * (16 / r.selected_layers) for r in results)
        return (max_layer_time - actual_time) / max_layer_time if max_layer_time > 0 else 0
        
    def _calculate_memory_savings(self, results: List[RecommendationResult]) -> float:
        """è®¡ç®—ç›¸å¯¹äºæœ€å¤§å±‚æ•°çš„å†…å­˜èŠ‚çœ"""
        actual_memory = sum(r.memory_usage_mb for r in results)
        max_layer_memory = sum(r.memory_usage_mb * (16 / r.selected_layers) for r in results)
        return (max_layer_memory - actual_memory) / max_layer_memory if max_layer_memory > 0 else 0

def create_test_scenarios() -> List[UserContext]:
    """åˆ›å»ºæµ‹è¯•åœºæ™¯"""
    scenarios = [
        # ç§»åŠ¨ç«¯åœºæ™¯
        UserContext("user_001", "è½»è–„ç¬”è®°æœ¬ç”µè„‘", "Electronics", "mobile", 50.0, 100.0),
        UserContext("user_002", "è¿åŠ¨é‹", "Sports", "mobile", 50.0, 100.0),
        UserContext("user_003", "å°è¯´", "Books", "mobile", 50.0, 100.0),
        
        # è¾¹ç¼˜è®¡ç®—åœºæ™¯
        UserContext("user_004", "æ™ºèƒ½å®¶å±…è®¾å¤‡æ¨è", "Electronics", "edge", 100.0, 500.0),
        UserContext("user_005", "åŠå…¬ç”¨å“æ‰¹é‡é‡‡è´­", "Home", "edge", 100.0, 500.0),
        UserContext("user_006", "ä¸“ä¸šæ‘„å½±è®¾å¤‡", "Electronics", "edge", 100.0, 500.0),
        
        # äº‘ç«¯åœºæ™¯
        UserContext("user_007", "é«˜ç«¯æ¸¸æˆè®¾å¤‡å®šåˆ¶åŒ–æ¨èæ–¹æ¡ˆ", "Electronics", "cloud", 200.0, 2000.0),
        UserContext("user_008", "ä¼ä¸šçº§æœè£…é‡‡è´­è§£å†³æ–¹æ¡ˆ", "Clothing", "cloud", 200.0, 2000.0),
        UserContext("user_009", "å…¨æ–¹ä½å¥èº«å™¨æé…å¥—æ¨è", "Sports", "cloud", 200.0, 2000.0),
        UserContext("user_010", "ä¸“ä¸šå¨æˆ¿è®¾å¤‡æ•´ä½“æ–¹æ¡ˆ", "Home", "cloud", 200.0, 2000.0),
    ]
    
    return scenarios

def main():
    """ä¸»å‡½æ•° - åŠ¨æ€å±‚é€‰æ‹©æ¨èç³»ç»Ÿæ¼”ç¤º"""
    logger.info("ğŸ¬ å¼€å§‹åŠ¨æ€å±‚é€‰æ‹©æ¨èç³»ç»Ÿæ¼”ç¤º...")
    
    # åˆå§‹åŒ–æ¨èç³»ç»Ÿ
    recommender = DynamicRecommendationSystem()
    
    # åˆ›å»ºæµ‹è¯•åœºæ™¯
    test_scenarios = create_test_scenarios()
    
    # æ‰§è¡Œæ‰¹é‡æ¨è
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ”¥ æ‰§è¡Œæ‰¹é‡æ¨èæµ‹è¯•")
    logger.info(f"{'='*60}")
    
    results = recommender.batch_recommend(test_scenarios, top_k=5)
    
    # åˆ†ææ€§èƒ½
    performance_analysis = recommender.analyze_performance(results)
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“Š æ¨èç»“æœè¯¦æƒ…")
    logger.info(f"{'='*60}")
    
    for i, (scenario, result) in enumerate(zip(test_scenarios, results)):
        logger.info(f"\nã€åœºæ™¯ {i+1}ã€‘{scenario.device_type.upper()} - {scenario.query}")
        logger.info(f"  ğŸ¯ é€‰æ‹©å±‚æ•°: {result.selected_layers}")
        logger.info(f"  ğŸ“Š å¤æ‚åº¦: {result.complexity_score:.3f}")
        logger.info(f"  âš¡ æ¨ç†æ—¶é—´: {result.inference_time_ms:.1f}ms")
        logger.info(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {result.memory_usage_mb:.1f}MB")
        logger.info(f"  ğŸ† è´¨é‡ä¼°ç®—: {result.quality_estimate:.3f}")
        logger.info(f"  ğŸ“¦ æ¨èç‰©å“: {result.items[:3]}")  # æ˜¾ç¤ºå‰3ä¸ªæ¨è
    
    # è¾“å‡ºæ€§èƒ½åˆ†æ
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“ˆ æ•´ä½“æ€§èƒ½åˆ†æ")
    logger.info(f"{'='*60}")
    
    logger.info(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {performance_analysis['total_requests']}")
    logger.info(f"âš¡ å¹³å‡æ¨ç†æ—¶é—´: {performance_analysis['avg_inference_time_ms']:.1f}ms")
    logger.info(f"ğŸ’¾ å¹³å‡å†…å­˜ä½¿ç”¨: {performance_analysis['avg_memory_usage_mb']:.1f}MB")
    logger.info(f"ğŸ¯ å¹³å‡è´¨é‡è¯„åˆ†: {performance_analysis['avg_quality_estimate']:.3f}")
    
    logger.info(f"\nğŸ—ï¸ å±‚æ•°ä½¿ç”¨åˆ†å¸ƒ:")
    for layers, count in sorted(performance_analysis['layer_usage_distribution'].items()):
        percentage = count / performance_analysis['total_requests'] * 100
        logger.info(f"  {layers} å±‚: {count} æ¬¡ ({percentage:.1f}%)")
    
    efficiency = performance_analysis['efficiency_metrics']
    logger.info(f"\nâš¡ æ•ˆç‡æŒ‡æ ‡:")
    logger.info(f"  æ—¶é—´èŠ‚çœç‡: {efficiency['total_time_saved_vs_max_layers']:.1%}")
    logger.info(f"  å†…å­˜èŠ‚çœç‡: {efficiency['total_memory_saved_vs_max_layers']:.1%}")
    logger.info(f"  è´¨é‡ä¿æŒç‡: {efficiency['quality_retention_rate']:.1%}")
    
    # ä¿å­˜ç»“æœ
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    results_dir = Path('results/dynamic_layer_selection')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        'timestamp': timestamp,
        'scenarios': [
            {
                'user_id': s.user_id,
                'query': s.query,
                'category': s.category,
                'device_type': s.device_type,
                'result': {
                    'selected_layers': r.selected_layers,
                    'complexity_score': r.complexity_score,
                    'inference_time_ms': r.inference_time_ms,
                    'memory_usage_mb': r.memory_usage_mb,
                    'quality_estimate': r.quality_estimate,
                    'top_items': r.items
                }
            }
            for s, r in zip(test_scenarios, results)
        ],
        'performance_analysis': performance_analysis
    }
    
    results_file = results_dir / f'dynamic_recommendation_demo_{timestamp}.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {results_file}")
    logger.info(f"ğŸ‰ åŠ¨æ€å±‚é€‰æ‹©æ¨èç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")

if __name__ == "__main__":
    main()
