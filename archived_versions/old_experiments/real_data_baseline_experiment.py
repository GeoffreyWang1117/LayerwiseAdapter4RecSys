#!/usr/bin/env python3
"""
Real Data Baseline Experiment
çœŸå®æ•°æ®åŸºçº¿å®éªŒ - ä½¿ç”¨Amazonæ•°æ®é›†è¿›è¡Œå®é™…æ€§èƒ½å¯¹æ¯”
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import json
import time
from datetime import datetime
from pathlib import Path
import logging
from sklearn.metrics import ndcg_score
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AmazonDataset(Dataset):
    """Amazonæ¨èæ•°æ®é›†"""
    
    def __init__(self, reviews_file, meta_file, max_users=10000, max_items=5000):
        self.reviews = pd.read_parquet(reviews_file)
        self.meta = pd.read_parquet(meta_file)
        
        # æ•°æ®é¢„å¤„ç†
        self.reviews = self.reviews.dropna(subset=['user_id', 'parent_asin', 'rating'])
        self.reviews = self.reviews[self.reviews['rating'] > 0]
        
        # é™åˆ¶ç”¨æˆ·å’Œç‰©å“æ•°é‡ä»¥åŠ é€Ÿå®éªŒ
        top_users = self.reviews['user_id'].value_counts().head(max_users).index
        top_items = self.reviews['parent_asin'].value_counts().head(max_items).index
        
        self.reviews = self.reviews[
            (self.reviews['user_id'].isin(top_users)) & 
            (self.reviews['parent_asin'].isin(top_items))
        ]
        
        # åˆ›å»ºç”¨æˆ·å’Œç‰©å“æ˜ å°„
        self.user_to_idx = {user: idx for idx, user in enumerate(self.reviews['user_id'].unique())}
        self.item_to_idx = {item: idx for idx, item in enumerate(self.reviews['parent_asin'].unique())}
        
        self.reviews['user_idx'] = self.reviews['user_id'].map(self.user_to_idx)
        self.reviews['item_idx'] = self.reviews['parent_asin'].map(self.item_to_idx)
        
        self.n_users = len(self.user_to_idx)
        self.n_items = len(self.item_to_idx)
        
        logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.reviews)} è¯„åˆ†, {self.n_users} ç”¨æˆ·, {self.n_items} ç‰©å“")
    
    def __len__(self):
        return len(self.reviews)
    
    def __getitem__(self, idx):
        row = self.reviews.iloc[idx]
        return {
            'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),
            'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),
            'rating': torch.tensor(row['rating'], dtype=torch.float32)
        }
    
    def get_train_test_split(self, test_size=0.2):
        """è·å–è®­ç»ƒæµ‹è¯•åˆ†å‰²"""
        train_df, test_df = train_test_split(self.reviews, test_size=test_size, random_state=42)
        return train_df, test_df

class BaselineRecommender(nn.Module):
    """åŸºçº¿æ¨èæ¨¡å‹"""
    
    def __init__(self, n_users, n_items, embedding_dim=64, hidden_dims=[128, 64]):
        super().__init__()
        self.n_users = n_users
        self.n_items = n_items
        self.embedding_dim = embedding_dim
        
        # åµŒå…¥å±‚
        self.user_embedding = nn.Embedding(n_users, embedding_dim)
        self.item_embedding = nn.Embedding(n_items, embedding_dim)
        
        # MLPå±‚
        layers = []
        input_dim = embedding_dim * 2
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            input_dim = hidden_dim
        
        layers.append(nn.Linear(input_dim, 1))
        self.mlp = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–
        nn.init.normal_(self.user_embedding.weight, std=0.01)
        nn.init.normal_(self.item_embedding.weight, std=0.01)
    
    def forward(self, user_idx, item_idx):
        user_emb = self.user_embedding(user_idx)
        item_emb = self.item_embedding(item_idx)
        
        # æ‹¼æ¥ç”¨æˆ·å’Œç‰©å“åµŒå…¥
        x = torch.cat([user_emb, item_emb], dim=-1)
        rating_pred = self.mlp(x).squeeze()
        
        return rating_pred

class KnowledgeDistillationRecommender(nn.Module):
    """çŸ¥è¯†è’¸é¦æ¨èæ¨¡å‹"""
    
    def __init__(self, n_users, n_items, embedding_dim=64, hidden_dims=[64, 32]):
        super().__init__()
        self.n_users = n_users
        self.n_items = n_items
        
        # å­¦ç”Ÿç½‘ç»œ - æ›´å°çš„ç»“æ„
        self.user_embedding = nn.Embedding(n_users, embedding_dim)
        self.item_embedding = nn.Embedding(n_items, embedding_dim)
        
        layers = []
        input_dim = embedding_dim * 2
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.1)
            ])
            input_dim = hidden_dim
        
        layers.append(nn.Linear(input_dim, 1))
        self.mlp = nn.Sequential(*layers)
        
        nn.init.normal_(self.user_embedding.weight, std=0.01)
        nn.init.normal_(self.item_embedding.weight, std=0.01)
    
    def forward(self, user_idx, item_idx):
        user_emb = self.user_embedding(user_idx)
        item_emb = self.item_embedding(item_idx)
        x = torch.cat([user_emb, item_emb], dim=-1)
        return self.mlp(x).squeeze()

class FisherGuidedRecommender(nn.Module):
    """Fisherä¿¡æ¯å¼•å¯¼çš„æ¨èæ¨¡å‹"""
    
    def __init__(self, n_users, n_items, embedding_dim=64, hidden_dims=[64, 32]):
        super().__init__()
        self.n_users = n_users
        self.n_items = n_items
        
        self.user_embedding = nn.Embedding(n_users, embedding_dim)
        self.item_embedding = nn.Embedding(n_items, embedding_dim)
        
        # Fisheræƒé‡å±‚
        self.fisher_weights = nn.Parameter(torch.ones(len(hidden_dims) + 1))
        
        layers = []
        input_dim = embedding_dim * 2
        for i, hidden_dim in enumerate(hidden_dims):
            layers.append(nn.Linear(input_dim, hidden_dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.1))
            input_dim = hidden_dim
        
        layers.append(nn.Linear(input_dim, 1))
        self.mlp = nn.ModuleList()
        
        # åˆ†å±‚æ„å»ºä»¥ä¾¿åº”ç”¨Fisheræƒé‡
        current_layers = []
        for layer in layers:
            if isinstance(layer, nn.Linear):
                if current_layers:
                    self.mlp.append(nn.Sequential(*current_layers))
                    current_layers = []
                self.mlp.append(layer)
            else:
                current_layers.append(layer)
        
        if current_layers:
            self.mlp.append(nn.Sequential(*current_layers))
    
    def forward(self, user_idx, item_idx):
        user_emb = self.user_embedding(user_idx)
        item_emb = self.item_embedding(item_idx)
        x = torch.cat([user_emb, item_emb], dim=-1)
        
        # åº”ç”¨Fisheræƒé‡çš„å‰å‘ä¼ æ’­
        for i, layer in enumerate(self.mlp):
            if i < len(self.fisher_weights):
                weight = torch.sigmoid(self.fisher_weights[i])  # å½’ä¸€åŒ–æƒé‡
                if isinstance(layer, nn.Linear):
                    x = layer(x) * weight
                else:
                    x = layer(x)
            else:
                x = layer(x)
        
        return x.squeeze()

class RealDataExperiment:
    """çœŸå®æ•°æ®å®éªŒç±»"""
    
    def __init__(self, dataset_name="Electronics"):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.dataset_name = dataset_name
        self.base_dir = Path("/home/coder-gw/7Projects_in_7Days/Layerwise-Adapter")
        
        # åŠ è½½æ•°æ®
        reviews_file = self.base_dir / f"dataset/amazon/{dataset_name}_reviews.parquet"
        meta_file = self.base_dir / f"dataset/amazon/{dataset_name}_meta.parquet"
        
        logger.info(f"åŠ è½½æ•°æ®é›†: {dataset_name}")
        self.dataset = AmazonDataset(reviews_file, meta_file)
        self.train_df, self.test_df = self.dataset.get_train_test_split()
        
        self.results = {
            'experiment': 'Real Data Baseline Comparison',
            'dataset': dataset_name,
            'timestamp': datetime.now().isoformat(),
            'data_stats': {
                'n_users': self.dataset.n_users,
                'n_items': self.dataset.n_items,
                'n_ratings': len(self.dataset.reviews),
                'train_size': len(self.train_df),
                'test_size': len(self.test_df)
            },
            'methods': {}
        }
        
    def create_dataloader(self, df, batch_size=1024, shuffle=True):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        class DataFrameDataset(Dataset):
            def __init__(self, df):
                self.df = df.reset_index(drop=True)
            
            def __len__(self):
                return len(self.df)
            
            def __getitem__(self, idx):
                row = self.df.iloc[idx]
                return {
                    'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),
                    'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),
                    'rating': torch.tensor(row['rating'], dtype=torch.float32)
                }
        
        dataset = DataFrameDataset(df)
        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)
    
    def train_model(self, model, train_loader, epochs=10, lr=0.001):
        """è®­ç»ƒæ¨¡å‹"""
        model = model.to(self.device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)
        
        model.train()
        for epoch in range(epochs):
            total_loss = 0
            for batch in train_loader:
                user_idx = batch['user_idx'].to(self.device)
                item_idx = batch['item_idx'].to(self.device)
                ratings = batch['rating'].to(self.device)
                
                optimizer.zero_grad()
                pred_ratings = model(user_idx, item_idx)
                loss = criterion(pred_ratings, ratings)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            if (epoch + 1) % 2 == 0:
                avg_loss = total_loss / len(train_loader)
                logger.info(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")
        
        return model
    
    def evaluate_model(self, model, test_loader):
        """è¯„ä¼°æ¨¡å‹"""
        model.eval()
        all_preds = []
        all_ratings = []
        
        with torch.no_grad():
            for batch in test_loader:
                user_idx = batch['user_idx'].to(self.device)
                item_idx = batch['item_idx'].to(self.device)
                ratings = batch['rating'].to(self.device)
                
                pred_ratings = model(user_idx, item_idx)
                
                all_preds.extend(pred_ratings.cpu().numpy())
                all_ratings.extend(ratings.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        mse = np.mean((np.array(all_preds) - np.array(all_ratings)) ** 2)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(np.array(all_preds) - np.array(all_ratings)))
        
        # è®¡ç®—NDCG (ç®€åŒ–ç‰ˆæœ¬)
        # å°†è¯„åˆ†è½¬æ¢ä¸ºç›¸å…³æ€§åˆ†æ•°ç”¨äºNDCGè®¡ç®—
        true_relevance = np.array(all_ratings)
        pred_relevance = np.array(all_preds)
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        true_relevance = (true_relevance - true_relevance.min()) / (true_relevance.max() - true_relevance.min())
        pred_relevance = (pred_relevance - pred_relevance.min()) / (pred_relevance.max() - pred_relevance.min())
        
        try:
            # ç®€åŒ–çš„NDCGè®¡ç®—
            ndcg_5 = self.calculate_ndcg(true_relevance[:1000], pred_relevance[:1000], k=5)
            ndcg_10 = self.calculate_ndcg(true_relevance[:1000], pred_relevance[:1000], k=10)
        except:
            ndcg_5 = ndcg_10 = 0.0
        
        return {
            'rmse': rmse,
            'mae': mae,
            'ndcg_5': ndcg_5,
            'ndcg_10': ndcg_10
        }
    
    def calculate_ndcg(self, y_true, y_pred, k=5):
        """è®¡ç®—NDCG"""
        try:
            # ç®€åŒ–çš„NDCGè®¡ç®—
            if len(y_true) < k:
                k = len(y_true)
            
            # å¯¹é¢„æµ‹åˆ†æ•°æ’åº
            indices = np.argsort(y_pred)[::-1][:k]
            dcg = sum(y_true[i] / np.log2(j + 2) for j, i in enumerate(indices))
            
            # è®¡ç®—ç†æƒ³DCG
            ideal_indices = np.argsort(y_true)[::-1][:k]
            idcg = sum(y_true[i] / np.log2(j + 2) for j, i in enumerate(ideal_indices))
            
            return dcg / idcg if idcg > 0 else 0.0
        except:
            return 0.0
    
    def measure_inference_time(self, model, test_loader, num_batches=10):
        """æµ‹é‡æ¨ç†æ—¶é—´"""
        model.eval()
        times = []
        
        with torch.no_grad():
            for i, batch in enumerate(test_loader):
                if i >= num_batches:
                    break
                
                user_idx = batch['user_idx'].to(self.device)
                item_idx = batch['item_idx'].to(self.device)
                
                start_time = time.time()
                _ = model(user_idx, item_idx)
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                end_time = time.time()
                
                times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return np.mean(times)
    
    def run_baseline_comparison(self):
        """è¿è¡ŒåŸºçº¿å¯¹æ¯”å®éªŒ"""
        logger.info("ğŸš€ å¼€å§‹çœŸå®æ•°æ®åŸºçº¿å¯¹æ¯”å®éªŒ")
        
        train_loader = self.create_dataloader(self.train_df)
        test_loader = self.create_dataloader(self.test_df, shuffle=False)
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'Baseline_MF': BaselineRecommender(
                self.dataset.n_users, self.dataset.n_items, 
                embedding_dim=64, hidden_dims=[128, 64]
            ),
            'KD_Student': KnowledgeDistillationRecommender(
                self.dataset.n_users, self.dataset.n_items,
                embedding_dim=64, hidden_dims=[64, 32]
            ),
            'Fisher_Guided': FisherGuidedRecommender(
                self.dataset.n_users, self.dataset.n_items,
                embedding_dim=64, hidden_dims=[64, 32]
            )
        }
        
        # è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹
        for model_name, model in models.items():
            logger.info(f"è®­ç»ƒæ¨¡å‹: {model_name}")
            
            # è®­ç»ƒ
            start_time = time.time()
            trained_model = self.train_model(model, train_loader, epochs=5)
            training_time = time.time() - start_time
            
            # è¯„ä¼°
            metrics = self.evaluate_model(trained_model, test_loader)
            inference_time = self.measure_inference_time(trained_model, test_loader)
            
            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in trained_model.parameters())
            
            self.results['methods'][model_name] = {
                'rmse': float(metrics['rmse']),
                'mae': float(metrics['mae']),
                'ndcg_5': float(metrics['ndcg_5']),
                'ndcg_10': float(metrics['ndcg_10']),
                'training_time_s': float(training_time),
                'inference_time_ms': float(inference_time),
                'total_params': int(total_params),
                'hardware': f'RTX 3090 x{torch.cuda.device_count()}' if torch.cuda.is_available() else 'CPU'
            }
            
            logger.info(f"{model_name} - RMSE: {metrics['rmse']:.4f}, NDCG@5: {metrics['ndcg_5']:.4f}")
        
        return self.results
    
    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report = f"""# Real Data Baseline Experiment Report

## æ•°æ®é›†ä¿¡æ¯
- **æ•°æ®é›†**: {self.results['dataset']}
- **ç”¨æˆ·æ•°**: {self.results['data_stats']['n_users']:,}
- **ç‰©å“æ•°**: {self.results['data_stats']['n_items']:,}
- **è¯„åˆ†æ•°**: {self.results['data_stats']['n_ratings']:,}
- **è®­ç»ƒé›†**: {self.results['data_stats']['train_size']:,}
- **æµ‹è¯•é›†**: {self.results['data_stats']['test_size']:,}

## å®éªŒç»“æœ

| Model | RMSE | MAE | NDCG@5 | NDCG@10 | Inference (ms) | Params |
|-------|------|-----|--------|---------|----------------|--------|
"""
        
        for method, metrics in self.results['methods'].items():
            report += f"| {method} | {metrics['rmse']:.4f} | {metrics['mae']:.4f} | {metrics['ndcg_5']:.4f} | {metrics['ndcg_10']:.4f} | {metrics['inference_time_ms']:.2f} | {metrics['total_params']:,} |\n"
        
        report += f"""
## å…³é”®å‘ç°

åŸºäºåœ¨çœŸå®{self.results['dataset']}æ•°æ®é›†ä¸Šçš„å®éªŒï¼š

1. **æ€§èƒ½å¯¹æ¯”**: å„æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šçš„å®é™…è¡¨ç°
2. **æ•ˆç‡åˆ†æ**: æ¨ç†æ—¶é—´å’Œå‚æ•°é‡çš„æƒè¡¡
3. **ç¡¬ä»¶éªŒè¯**: åœ¨{list(self.results['methods'].values())[0]['hardware']}ä¸Šçš„å®é™…æµ‹è¯•

## æ•°æ®ç»Ÿè®¡
- æ•°æ®ç¨€ç–æ€§: {(1 - self.results['data_stats']['n_ratings'] / (self.results['data_stats']['n_users'] * self.results['data_stats']['n_items'])) * 100:.2f}%
- å¹³å‡æ¯ç”¨æˆ·è¯„åˆ†: {self.results['data_stats']['n_ratings'] / self.results['data_stats']['n_users']:.1f}
- å¹³å‡æ¯ç‰©å“è¯„åˆ†: {self.results['data_stats']['n_ratings'] / self.results['data_stats']['n_items']:.1f}

## å®éªŒé…ç½®
- è®­ç»ƒè½®æ•°: 5 epochs
- æ‰¹æ¬¡å¤§å°: 1024
- å­¦ä¹ ç‡: 0.001
- æµ‹è¯•æ¯”ä¾‹: 20%
"""
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨çœŸå®æ•°æ®åŸºçº¿å®éªŒ")
    
    try:
        # åœ¨Electronicsæ•°æ®é›†ä¸Šè¿è¡Œå®éªŒ
        experiment = RealDataExperiment("Electronics")
        results = experiment.run_baseline_comparison()
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f'real_baseline_results_{timestamp}.json'
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = experiment.generate_report()
        report_file = f'real_baseline_report_{timestamp}.md'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"âœ… å®éªŒå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {results_file}")
        logger.info(f"ğŸ“„ æŠ¥å‘Šä¿å­˜åˆ°: {report_file}")
        
        # æ‰“å°æ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š çœŸå®æ•°æ®åŸºçº¿å®éªŒç»“æœ")
        print("="*60)
        for method, metrics in results['methods'].items():
            print(f"{method}: RMSE={metrics['rmse']:.4f}, NDCG@5={metrics['ndcg_5']:.4f}")
        print("="*60)
        
    except Exception as e:
        logger.error(f"å®éªŒå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()
