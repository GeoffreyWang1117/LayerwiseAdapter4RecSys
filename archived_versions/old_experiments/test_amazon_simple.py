"""
ç‹¬ç«‹çš„Amazonæ•°æ®å¤„ç†æµ‹è¯•è„šæœ¬
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
import logging
from sklearn.preprocessing import LabelEncoder
from scipy.sparse import csr_matrix
import warnings

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

@dataclass
class DataConfig:
    """æ•°æ®å¤„ç†é…ç½®"""
    min_user_interactions: int = 5
    min_item_interactions: int = 5  
    test_ratio: float = 0.2
    val_ratio: float = 0.1   
    random_seed: int = 42    
    max_users: Optional[int] = None  
    max_items: Optional[int] = None  

class SimpleAmazonProcessor:
    """ç®€åŒ–çš„Amazonæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_path: str = "dataset/amazon", config: Optional[DataConfig] = None):
        self.data_path = Path(data_path)
        self.config = config or DataConfig()
        self.logger = logging.getLogger(self.__class__.__name__)
        
        self.available_categories = [
            'All_Beauty', 'Electronics', 'Books', 'Movies_and_TV', 
            'Home_and_Kitchen', 'Arts_Crafts_and_Sewing', 'Automotive',
            'Office_Products', 'Sports_and_Outdoors', 'Toys_and_Games'
        ]
        
        self.user_encoder = LabelEncoder()
        self.item_encoder = LabelEncoder()
        
    def get_available_categories(self) -> List[str]:
        """è·å–å¯ç”¨çš„äº§å“ç±»åˆ«"""
        available = []
        for category in self.available_categories:
            reviews_file = self.data_path / f"{category}_reviews.parquet"
            if reviews_file.exists():
                available.append(category)
        return available
    
    def load_category_data(self, category: str) -> pd.DataFrame:
        """åŠ è½½æŒ‡å®šç±»åˆ«çš„æ•°æ®"""
        reviews_file = self.data_path / f"{category}_reviews.parquet"
        
        if not reviews_file.exists():
            raise FileNotFoundError(f"è¯„è®ºæ–‡ä»¶ä¸å­˜åœ¨: {reviews_file}")
        
        self.logger.info(f"åŠ è½½ç±»åˆ« {category} çš„æ•°æ®...")
        reviews_df = pd.read_parquet(reviews_file)
        self.logger.info(f"åŠ è½½äº† {len(reviews_df):,} æ¡è¯„è®ºè®°å½•")
        
        return reviews_df
    
    def normalize_reviews_data(self, reviews_df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–è¯„è®ºæ•°æ®æ ¼å¼"""
        # ç»Ÿä¸€åˆ—å
        column_mapping = {
            'parent_asin': 'item_id',
            'asin': 'item_id',
            'user_id': 'user_id',
            'rating': 'rating',
            'timestamp': 'timestamp',
        }
        
        # æ‰¾åˆ°å®é™…å­˜åœ¨çš„åˆ—
        available_columns = {}
        for old_col, new_col in column_mapping.items():
            if old_col in reviews_df.columns:
                available_columns[old_col] = new_col
        
        # é‡å‘½ååˆ—
        normalized_df = reviews_df.rename(columns=available_columns)
        
        # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
        required_columns = ['user_id', 'item_id', 'rating']
        missing_columns = [col for col in required_columns if col not in normalized_df.columns]
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        
        # æ•°æ®æ¸…ç†
        normalized_df = normalized_df.dropna(subset=['user_id', 'item_id', 'rating'])
        normalized_df = normalized_df[
            (normalized_df['rating'] >= 1) & (normalized_df['rating'] <= 5)
        ]
        
        self.logger.info(f"æ ‡å‡†åŒ–åä¿ç•™ {len(normalized_df):,} æ¡è®°å½•")
        return normalized_df
    
    def filter_interactions(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿‡æ»¤ä½é¢‘ç”¨æˆ·å’Œç‰©å“"""
        original_size = len(df)
        
        # è¿‡æ»¤ä½é¢‘ç”¨æˆ·
        if 'user_id' in df.columns:
            user_counts = df['user_id'].value_counts()
            valid_users = user_counts[user_counts >= self.config.min_user_interactions].index
            df = df[df['user_id'].isin(valid_users)]
        
        # è¿‡æ»¤ä½é¢‘ç‰©å“
        if 'item_id' in df.columns:
            item_counts = df['item_id'].value_counts()
            valid_items = item_counts[item_counts >= self.config.min_item_interactions].index
            df = df[df['item_id'].isin(valid_items)]
        
        # é™åˆ¶ç”¨æˆ·å’Œç‰©å“æ•°é‡
        if self.config.max_users is not None:
            top_users = df['user_id'].value_counts().head(self.config.max_users).index
            df = df[df['user_id'].isin(top_users)]
        
        if self.config.max_items is not None:
            top_items = df['item_id'].value_counts().head(self.config.max_items).index
            df = df[df['item_id'].isin(top_items)]
        
        filtered_size = len(df)
        self.logger.info(
            f"è¿‡æ»¤åä¿ç•™ {filtered_size:,} æ¡è®°å½• "
            f"({filtered_size/original_size*100:.1f}%)"
        )
        
        return df
    
    def encode_ids(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç¼–ç ç”¨æˆ·å’Œç‰©å“ID"""
        df = df.copy()
        
        # ç¼–ç ç”¨æˆ·ID
        df['user_idx'] = self.user_encoder.fit_transform(df['user_id'])
        
        # ç¼–ç ç‰©å“ID  
        df['item_idx'] = self.item_encoder.fit_transform(df['item_id'])
        
        self.logger.info(
            f"ç¼–ç å®Œæˆ: {len(self.user_encoder.classes_):,} ä¸ªç”¨æˆ·, "
            f"{len(self.item_encoder.classes_):,} ä¸ªç‰©å“"
        )
        
        return df
    
    def create_interaction_matrix(self, df: pd.DataFrame) -> csr_matrix:
        """åˆ›å»ºç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µ"""
        n_users = df['user_idx'].max() + 1
        n_items = df['item_idx'].max() + 1
        
        # åˆ›å»ºç¨€ç–çŸ©é˜µ
        interaction_matrix = csr_matrix(
            (df['rating'].values, (df['user_idx'].values, df['item_idx'].values)),
            shape=(n_users, n_items)
        )
        
        density = interaction_matrix.nnz / (n_users * n_items) * 100
        self.logger.info(
            f"äº¤äº’çŸ©é˜µ: {n_users:,} x {n_items:,}, "
            f"å¯†åº¦: {density:.4f}%, éé›¶å…ƒç´ : {interaction_matrix.nnz:,}"
        )
        
        return interaction_matrix
    
    def get_data_summary(self) -> pd.DataFrame:
        """è·å–æ‰€æœ‰å¯ç”¨ç±»åˆ«çš„æ•°æ®æ‘˜è¦"""
        categories = self.get_available_categories()
        summary_data = []
        
        for category in categories:
            try:
                reviews_df = self.load_category_data(category)
                normalized_df = self.normalize_reviews_data(reviews_df)
                
                n_users = normalized_df['user_id'].nunique()
                n_items = normalized_df['item_id'].nunique()
                
                summary_data.append({
                    'category': category,
                    'total_reviews': len(reviews_df),
                    'after_cleaning': len(normalized_df),
                    'n_users': n_users,
                    'n_items': n_items,
                    'avg_rating': normalized_df['rating'].mean(),
                    'density': len(normalized_df) / (n_users * n_items) * 100
                })
            except Exception as e:
                self.logger.warning(f"å¤„ç†ç±»åˆ« {category} æ—¶å‡ºé”™: {e}")
        
        return pd.DataFrame(summary_data)
    
    def process_category(self, category: str) -> Dict:
        """å¤„ç†æŒ‡å®šç±»åˆ«çš„å®Œæ•´æ•°æ®æµç¨‹"""
        self.logger.info(f"å¼€å§‹å¤„ç†ç±»åˆ«: {category}")
        
        # 1. åŠ è½½æ•°æ®
        reviews_df = self.load_category_data(category)
        
        # 2. æ ‡å‡†åŒ–æ•°æ®
        normalized_df = self.normalize_reviews_data(reviews_df)
        
        # 3. è¿‡æ»¤äº¤äº’
        filtered_df = self.filter_interactions(normalized_df)
        
        # 4. ç¼–ç ID
        encoded_df = self.encode_ids(filtered_df)
        
        # 5. åˆ›å»ºäº¤äº’çŸ©é˜µ
        interaction_matrix = self.create_interaction_matrix(encoded_df)
        
        # 6. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'category': category,
            'total_interactions': len(encoded_df),
            'n_users': len(self.user_encoder.classes_),
            'n_items': len(self.item_encoder.classes_),
            'density': interaction_matrix.nnz / (interaction_matrix.shape[0] * interaction_matrix.shape[1]) * 100,
            'avg_rating': encoded_df['rating'].mean(),
            'rating_std': encoded_df['rating'].std(),
        }
        
        result = {
            'stats': stats,
            'data': encoded_df,
            'matrix': interaction_matrix,
        }
        
        self.logger.info(f"ç±»åˆ« {category} å¤„ç†å®Œæˆ")
        return result

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•Amazonæ•°æ®å¤„ç†å™¨...")
    
    # åˆ›å»ºé…ç½®
    config = DataConfig(
        min_user_interactions=5,
        min_item_interactions=5,
        max_users=5000,   # é™åˆ¶ç”¨æˆ·æ•°ç”¨äºæµ‹è¯•
        max_items=2000    # é™åˆ¶ç‰©å“æ•°ç”¨äºæµ‹è¯•
    )
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = SimpleAmazonProcessor(config=config)
    
    # è·å–å¯ç”¨ç±»åˆ«
    categories = processor.get_available_categories()
    print(f"ğŸ“‹ å¯ç”¨ç±»åˆ«: {categories}")
    
    # è·å–æ•°æ®æ‘˜è¦
    print("\nğŸ“Š ç”Ÿæˆæ•°æ®æ‘˜è¦...")
    summary = processor.get_data_summary()
    print(summary.to_string(index=False))
    
    # é€‰æ‹©ä¸€ä¸ªè¾ƒå°çš„ç±»åˆ«è¿›è¡Œè¯¦ç»†æµ‹è¯•
    test_category = 'All_Beauty'  # ç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†
    
    if test_category in categories:
        print(f"\nğŸ” è¯¦ç»†å¤„ç†ç±»åˆ«: {test_category}")
        result = processor.process_category(test_category)
        
        # æ‰“å°å¤„ç†ç»“æœ
        print("\nğŸ“ˆ å¤„ç†ç»“æœç»Ÿè®¡:")
        stats = result['stats']
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value:,}" if isinstance(value, int) else f"  {key}: {value}")
        
        # åˆ†æè¯„åˆ†åˆ†å¸ƒ
        print("\nğŸ“Š è¯„åˆ†åˆ†å¸ƒ:")
        ratings = result['data']['rating'].values
        rating_counts = pd.Series(ratings).value_counts().sort_index()
        for rating, count in rating_counts.items():
            print(f"  è¯„åˆ† {rating}: {count:,} æ¬¡ ({count/len(ratings)*100:.1f}%)")
        
        print(f"\nâœ… ç±»åˆ« {test_category} å¤„ç†å®Œæˆ!")
        return result
    else:
        print(f"âŒ æµ‹è¯•ç±»åˆ« {test_category} ä¸å¯ç”¨")
        return None

if __name__ == "__main__":
    result = test_data_processor()
    print("\nğŸ‰ æ•°æ®å¤„ç†å™¨æµ‹è¯•å®Œæˆ!")
