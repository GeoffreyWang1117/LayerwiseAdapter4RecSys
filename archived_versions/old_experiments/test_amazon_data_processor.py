"""
æµ‹è¯•Amazonæ•°æ®å¤„ç†å™¨
"""

import sys
import os
sys.path.insert(0, os.path.abspath('.'))

import logging
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from sklearn.preprocessing import LabelEncoder
from scipy.sparse import csr_matrix
import warnings

warnings.filterwarnings('ignore')

# ç›´æ¥åŒ…å«å¿…è¦çš„ç±»å®šä¹‰
@dataclass
class DataConfig:
    """æ•°æ®å¤„ç†é…ç½®"""
    min_user_interactions: int = 5
    min_item_interactions: int = 5  
    test_ratio: float = 0.2
    val_ratio: float = 0.1
    random_seed: int = 42
    max_users: Optional[int] = None
    max_items: Optional[int] = None
import pandas as pd
import numpy as np

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•Amazonæ•°æ®å¤„ç†å™¨...")
    
    # åˆ›å»ºé…ç½®
    config = DataConfig(
        min_user_interactions=5,
        min_item_interactions=5,
        test_ratio=0.2,
        val_ratio=0.1,
        max_users=10000,  # é™åˆ¶ç”¨æˆ·æ•°ç”¨äºæµ‹è¯•
        max_items=5000    # é™åˆ¶ç‰©å“æ•°ç”¨äºæµ‹è¯•
    )
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = AmazonDataProcessor(config=config)
    
    # è·å–å¯ç”¨ç±»åˆ«
    categories = processor.get_available_categories()
    print(f"ğŸ“‹ å¯ç”¨ç±»åˆ«: {categories}")
    
    # è·å–æ•°æ®æ‘˜è¦
    print("\nğŸ“Š ç”Ÿæˆæ•°æ®æ‘˜è¦...")
    summary = processor.get_data_summary()
    print(summary.to_string(index=False))
    
    # é€‰æ‹©ä¸€ä¸ªè¾ƒå°çš„ç±»åˆ«è¿›è¡Œè¯¦ç»†æµ‹è¯•
    test_category = 'All_Beauty'  # ç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†
    
    if test_category in categories:
        print(f"\nğŸ” è¯¦ç»†å¤„ç†ç±»åˆ«: {test_category}")
        result = processor.process_category(test_category)
        
        # æ‰“å°å¤„ç†ç»“æœ
        print("\nğŸ“ˆ å¤„ç†ç»“æœç»Ÿè®¡:")
        stats = result['stats']
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value:,}" if isinstance(value, int) else f"  {key}: {value}")
        
        # åˆ†æç¨€ç–æ€§
        print("\nğŸ” ç¨€ç–æ€§åˆ†æ:")
        sparsity_metrics = DataUtils.calculate_sparsity_metrics(result['matrix'])
        for key, value in sparsity_metrics.items():
            print(f"  {key}: {value:.4f}")
        
        # åˆ†æè¯„åˆ†åˆ†å¸ƒ
        print("\nğŸ“Š è¯„åˆ†åˆ†å¸ƒåˆ†æ:")
        ratings = result['data']['full']['rating'].values
        rating_analysis = DataUtils.analyze_rating_distribution(ratings)
        for key, value in rating_analysis.items():
            if key != 'distribution':
                print(f"  {key}: {value:.4f}" if isinstance(value, float) else f"  {key}: {value}")
        
        print(f"  è¯„åˆ†åˆ†å¸ƒ: {rating_analysis['distribution']}")
        
        # æ£€æŸ¥æ•°æ®åˆ’åˆ†
        print("\nğŸ—‚ï¸ æ•°æ®åˆ’åˆ†æ£€æŸ¥:")
        for split_name, split_data in result['data'].items():
            print(f"  {split_name}: {len(split_data):,} æ¡è®°å½•")
        
        print(f"\nâœ… ç±»åˆ« {test_category} å¤„ç†å®Œæˆ!")
        return result
    else:
        print(f"âŒ æµ‹è¯•ç±»åˆ« {test_category} ä¸å¯ç”¨")
        return None

if __name__ == "__main__":
    result = test_data_processor()
    print("\nğŸ‰ æ•°æ®å¤„ç†å™¨æµ‹è¯•å®Œæˆ!")
