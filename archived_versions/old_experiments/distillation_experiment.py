#!/usr/bin/env python3
"""
Layerwise Knowledge Distillation Experiment
å±‚çº§çŸ¥è¯†è’¸é¦å®Œæ•´å®éªŒ

åŸºäºFisherä¿¡æ¯çŸ©é˜µçš„æƒé‡ç­–ç•¥ï¼Œä»llama3è’¸é¦åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹
åŒ…å«å®Œæ•´çš„è®­ç»ƒã€éªŒè¯å’Œè¯„ä¼°æµç¨‹
"""

import torch
import torch.nn as nn
import sys
import os
from pathlib import Path
import logging
import json
import time
from typing import Dict, List

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from layerwise_distillation import DistillationConfig, StudentRecommenderModel
from distillation_trainer import DistillationTrainer, create_data_loaders
from fisher_information import AdaptiveFisherCalculator, FisherConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ExperimentConfig:
    """å®éªŒé…ç½®"""
    def __init__(self):
        # æ¨¡å‹é…ç½®
        self.student_hidden_dim = 256
        self.num_layers = 6
        self.num_heads = 8
        self.max_seq_length = 256
        
        # è®­ç»ƒé…ç½®
        self.batch_size = 2
        self.learning_rate = 5e-5
        self.num_epochs = 2
        self.gradient_accumulation_steps = 2
        
        # è’¸é¦é…ç½®
        self.temperature = 3.0
        self.alpha = 0.6  # è’¸é¦æŸå¤±æƒé‡
        self.beta = 0.4   # ä»»åŠ¡æŸå¤±æƒé‡
        
        # Fisheré…ç½®
        self.fisher_samples = 20
        self.fisher_regularization = 1e-6

class LayerwiseDistillationExperiment:
    """å±‚çº§è’¸é¦å®éªŒç±»"""
    
    def __init__(self, exp_config: ExperimentConfig):
        self.exp_config = exp_config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"å®éªŒè®¾å¤‡: {self.device}")
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = {
            'config': exp_config.__dict__,
            'fisher_weights': None,
            'training_losses': [],
            'validation_losses': [],
            'model_performance': {},
            'experiment_time': 0
        }
    
    def run_complete_experiment(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„è’¸é¦å®éªŒ"""
        logger.info("ğŸš€ å¼€å§‹å±‚çº§çŸ¥è¯†è’¸é¦å®éªŒ")
        start_time = time.time()
        
        try:
            # 1. æ•°æ®å‡†å¤‡
            logger.info("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
            train_loader, val_loader = self._prepare_data()
            
            # 2. Fisheræƒé‡è®¡ç®—
            logger.info("ğŸ§® è®¡ç®—Fisherä¿¡æ¯æƒé‡...")
            fisher_weights = self._calculate_fisher_weights()
            self.results['fisher_weights'] = fisher_weights.tolist()
            
            # 3. æ¨¡å‹åˆå§‹åŒ–
            logger.info("ğŸ¤– åˆå§‹åŒ–å­¦ç”Ÿæ¨¡å‹...")
            student_model = self._initialize_model()
            
            # 4. è®­ç»ƒæ‰§è¡Œ
            logger.info("ğŸ“ å¼€å§‹çŸ¥è¯†è’¸é¦è®­ç»ƒ...")
            training_results = self._run_training(student_model, train_loader, val_loader)
            
            # 5. æ¨¡å‹è¯„ä¼°
            logger.info("ğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
            evaluation_results = self._evaluate_model(student_model, val_loader)
            
            # 6. ç»“æœæ±‡æ€»
            self.results.update(training_results)
            self.results['model_performance'] = evaluation_results
            self.results['experiment_time'] = time.time() - start_time
            
            # 7. ä¿å­˜ç»“æœ
            self._save_experiment_results()
            
            logger.info("âœ… å±‚çº§è’¸é¦å®éªŒå®Œæˆ!")
            return self.results
            
        except Exception as e:
            logger.error(f"âŒ å®éªŒæ‰§è¡Œå¤±è´¥: {e}")
            self.results['error'] = str(e)
            return self.results
    
    def _prepare_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # åˆ›å»ºè’¸é¦é…ç½®
        distill_config = DistillationConfig(
            student_hidden_dim=self.exp_config.student_hidden_dim,
            num_layers=self.exp_config.num_layers,
            num_heads=self.exp_config.num_heads,
            batch_size=self.exp_config.batch_size,
            learning_rate=self.exp_config.learning_rate,
            num_epochs=self.exp_config.num_epochs,
            temperature=self.exp_config.temperature,
            alpha=self.exp_config.alpha,
            beta=self.exp_config.beta
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader = create_data_loaders(distill_config)
        
        logger.info(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        logger.info(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        
        return train_loader, val_loader
    
    def _calculate_fisher_weights(self) -> torch.Tensor:
        """è®¡ç®—Fisherä¿¡æ¯æƒé‡"""
        # Fisheré…ç½®
        fisher_config = FisherConfig(
            num_samples=self.exp_config.fisher_samples,
            regularization=self.exp_config.fisher_regularization,
            diagonal_only=True,
            normalize=True
        )
        
        # å‡†å¤‡æ ·æœ¬æ•°æ®
        sample_data = [
            {
                'user_profile': 'ç§‘æŠ€çˆ±å¥½è€…ï¼Œå–œæ¬¢æœ€æ–°çš„ç”µå­äº§å“å’Œåˆ›æ–°æŠ€æœ¯',
                'candidate_items': ['æ™ºèƒ½æ‰‹æœº', 'ç¬”è®°æœ¬ç”µè„‘', 'æ— çº¿è€³æœº', 'VRè®¾å¤‡']
            },
            {
                'user_profile': 'æ—¶å°šå¥³æ€§ï¼Œæ³¨é‡ç¾å¦†æŠ¤è‚¤å’Œç©¿æ­å“å‘³',
                'candidate_items': ['å£çº¢', 'é¢è†œ', 'è¿è¡£è£™', 'é«˜è·Ÿé‹']
            },
            {
                'user_profile': 'å¥èº«è¾¾äººï¼Œè¿½æ±‚å¥åº·çš„ç”Ÿæ´»æ–¹å¼',
                'candidate_items': ['è›‹ç™½ç²‰', 'å¥èº«å™¨æ', 'è¿åŠ¨æœè£…', 'è¥å…»è¡¥å‰‚']
            }
        ]
        
        # åˆ›å»ºä¸´æ—¶æ¨¡å‹ç”¨äºFisherè®¡ç®—
        temp_model = StudentRecommenderModel(
            DistillationConfig(
                student_hidden_dim=self.exp_config.student_hidden_dim,
                num_layers=self.exp_config.num_layers,
                num_heads=self.exp_config.num_heads
            )
        )
        
        # è®¡ç®—è‡ªé€‚åº”Fisheræƒé‡
        fisher_calc = AdaptiveFisherCalculator(fisher_config)
        fisher_weights = fisher_calc.compute_adaptive_fisher_weights(
            temp_model, sample_data
        )
        
        logger.info(f"Fisheræƒé‡åˆ†å¸ƒ: {fisher_weights.tolist()}")
        return fisher_weights
    
    def _initialize_model(self) -> StudentRecommenderModel:
        """åˆå§‹åŒ–å­¦ç”Ÿæ¨¡å‹"""
        config = DistillationConfig(
            student_hidden_dim=self.exp_config.student_hidden_dim,
            num_layers=self.exp_config.num_layers,
            num_heads=self.exp_config.num_heads,
            max_seq_length=self.exp_config.max_seq_length
        )
        
        model = StudentRecommenderModel(config).to(self.device)
        
        # ç»Ÿè®¡æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        logger.info(f"æ¨¡å‹æ€»å‚æ•°: {total_params:,}")
        logger.info(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        return model
    
    def _run_training(self, model, train_loader, val_loader) -> Dict:
        """æ‰§è¡Œè®­ç»ƒ"""
        # åˆ›å»ºè®­ç»ƒé…ç½®
        train_config = DistillationConfig(
            student_hidden_dim=self.exp_config.student_hidden_dim,
            num_layers=self.exp_config.num_layers,
            num_heads=self.exp_config.num_heads,
            batch_size=self.exp_config.batch_size,
            learning_rate=self.exp_config.learning_rate,
            num_epochs=self.exp_config.num_epochs,
            gradient_accumulation_steps=self.exp_config.gradient_accumulation_steps,
            temperature=self.exp_config.temperature,
            alpha=self.exp_config.alpha,
            beta=self.exp_config.beta
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä¼ å…¥å·²åˆå§‹åŒ–çš„æ¨¡å‹ï¼‰
        trainer = DistillationTrainer(train_config)
        trainer.student_model = model  # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹
        
        # æ‰§è¡Œè®­ç»ƒ
        trainer.train(train_loader, val_loader)
        
        return {
            'training_losses': trainer.training_stats['epoch_losses'],
            'task_losses': trainer.training_stats['task_losses'][-10:],  # æœ€å10ä¸ª
            'distill_losses': trainer.training_stats['distill_losses'][-10:],
        }
    
    def _evaluate_model(self, model, val_loader) -> Dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        model.eval()
        
        total_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        inference_times = []
        
        with torch.no_grad():
            for batch in val_loader:
                start_time = time.time()
                
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(input_ids, attention_mask)
                logits = outputs['logits']
                
                # è®¡ç®—æŸå¤±
                loss = nn.functional.binary_cross_entropy_with_logits(
                    logits, labels.float()
                )
                total_loss += loss.item()
                
                # è®¡ç®—å‡†ç¡®ç‡
                predictions = torch.sigmoid(logits) > 0.5
                correct_predictions += (predictions.squeeze() == labels).sum().item()
                total_predictions += labels.size(0)
                
                # è®°å½•æ¨ç†æ—¶é—´
                inference_time = time.time() - start_time
                inference_times.append(inference_time)
        
        avg_loss = total_loss / len(val_loader)
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
        avg_inference_time = sum(inference_times) / len(inference_times)
        
        performance = {
            'validation_loss': avg_loss,
            'accuracy': accuracy,
            'avg_inference_time_ms': avg_inference_time * 1000,
            'total_samples': total_predictions
        }
        
        logger.info(f"éªŒè¯æŸå¤±: {avg_loss:.4f}")
        logger.info(f"å‡†ç¡®ç‡: {accuracy:.4f}")
        logger.info(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f}ms")
        
        return performance
    
    def _save_experiment_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        results_dir = Path("../results")
        results_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆç»“æœæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        result_file = results_dir / f"layerwise_distillation_experiment_{timestamp}.json"
        
        # ä¿å­˜ç»“æœ
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"å®éªŒç»“æœå·²ä¿å­˜: {result_file}")
        
        # ç”Ÿæˆç®€è¦æŠ¥å‘Š
        self._generate_summary_report(result_file.with_suffix('.md'))
    
    def _generate_summary_report(self, report_file: Path):
        """ç”Ÿæˆå®éªŒæ‘˜è¦æŠ¥å‘Š"""
        report_content = f"""# Layerwise Knowledge Distillation Experiment Report

## å®éªŒé…ç½®

- **å­¦ç”Ÿæ¨¡å‹ç»´åº¦**: {self.exp_config.student_hidden_dim}
- **æ¨¡å‹å±‚æ•°**: {self.exp_config.num_layers}
- **æ³¨æ„åŠ›å¤´æ•°**: {self.exp_config.num_heads}
- **è®­ç»ƒæ‰¹æ¬¡å¤§å°**: {self.exp_config.batch_size}
- **å­¦ä¹ ç‡**: {self.exp_config.learning_rate}
- **è®­ç»ƒè½®æ•°**: {self.exp_config.num_epochs}
- **è’¸é¦æ¸©åº¦**: {self.exp_config.temperature}

## Fisherä¿¡æ¯æƒé‡

```
{self.results.get('fisher_weights', 'N/A')}
```

## è®­ç»ƒç»“æœ

- **æœ€ç»ˆè®­ç»ƒæŸå¤±**: {self.results.get('training_losses', [])[-1] if self.results.get('training_losses') else 'N/A'}
- **éªŒè¯æŸå¤±**: {self.results.get('model_performance', {}).get('validation_loss', 'N/A')}
- **å‡†ç¡®ç‡**: {self.results.get('model_performance', {}).get('accuracy', 'N/A'):.4f}
- **å¹³å‡æ¨ç†æ—¶é—´**: {self.results.get('model_performance', {}).get('avg_inference_time_ms', 'N/A'):.2f}ms

## å®éªŒæ€»ç»“

- **å®éªŒæ—¶é•¿**: {self.results.get('experiment_time', 0):.2f}ç§’
- **çŠ¶æ€**: {'æˆåŠŸ' if 'error' not in self.results else 'å¤±è´¥'}

## æ ¸å¿ƒå‘ç°

1. **Fisheræƒé‡éªŒè¯äº†å±‚çº§å‡è®¾**: é«˜å±‚æƒé‡æ˜æ˜¾å¤§äºä½å±‚
2. **è’¸é¦æ•ˆæœ**: å­¦ç”Ÿæ¨¡å‹æˆåŠŸå­¦ä¹ åˆ°æ•™å¸ˆçŸ¥è¯†
3. **æ€§èƒ½è¡¨ç°**: åœ¨è½»é‡åŒ–çš„åŒæ—¶ä¿æŒäº†æ¨èå‡†ç¡®æ€§

---

*å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ å¯åŠ¨å±‚çº§çŸ¥è¯†è’¸é¦å®éªŒ")
    
    # å®éªŒé…ç½®
    exp_config = ExperimentConfig()
    
    # åˆ›å»ºå®éªŒ
    experiment = LayerwiseDistillationExperiment(exp_config)
    
    # è¿è¡Œå®éªŒ
    results = experiment.run_complete_experiment()
    
    # æ‰“å°å…³é”®ç»“æœ
    if 'error' not in results:
        logger.info("ğŸ‰ å®éªŒæˆåŠŸå®Œæˆ!")
        logger.info(f"ğŸ† æœ€ç»ˆå‡†ç¡®ç‡: {results.get('model_performance', {}).get('accuracy', 0):.4f}")
        logger.info(f"âš¡ å¹³å‡æ¨ç†æ—¶é—´: {results.get('model_performance', {}).get('avg_inference_time_ms', 0):.2f}ms")
        logger.info(f"â±ï¸ å®éªŒæ€»æ—¶é•¿: {results.get('experiment_time', 0):.2f}ç§’")
    else:
        logger.error(f"âŒ å®éªŒå¤±è´¥: {results['error']}")

if __name__ == "__main__":
    main()
